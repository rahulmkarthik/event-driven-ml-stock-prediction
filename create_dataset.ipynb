{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0171e930",
   "metadata": {},
   "source": [
    "# Generating dataset for ML classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4efd24",
   "metadata": {},
   "source": [
    "## Imports and Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7b1f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ta.momentum import RSIIndicator\n",
    "from ta.volatility import AverageTrueRange\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# ─── CONFIG ────────────────────────────────────\n",
    "start_date = \"2004-01-01\"\n",
    "end_date   = \"2024-12-31\"\n",
    "horizon    = 1    # days ahead for the target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d83d1541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched 503 tickers, e.g.: ['MMM', 'AOS', 'ABT', 'ABBV', 'ACN', 'ADBE', 'AMD', 'AES', 'AFL', 'A']\n"
     ]
    }
   ],
   "source": [
    "def get_sp500_tickers():\n",
    "    \"\"\"\n",
    "    Scrape the current list of S&P 500 constituents from Wikipedia\n",
    "    and return a list of ticker symbols (periods replaced with hyphens).\n",
    "    \"\"\"\n",
    "    # URL of the S&P 500 companies list on Wikipedia\n",
    "    url = \"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\"\n",
    "    \n",
    "    # pandas will pick up the first table on the page\n",
    "    tables = pd.read_html(url)\n",
    "    df = tables[0]\n",
    "    \n",
    "    # 'Symbol' column holds the tickers\n",
    "    raw_tickers = df[\"Symbol\"].astype(str).tolist()\n",
    "    \n",
    "    # Replace any '.' with '-' (e.g. BRK.B → BRK-B) for yfinance compatibility\n",
    "    tickers = [t.replace(\".\", \"-\") for t in raw_tickers]\n",
    "    return tickers\n",
    "\n",
    "# Usage\n",
    "sp500_tickers = get_sp500_tickers()\n",
    "print(f\"Fetched {len(sp500_tickers)} tickers, e.g.: {sp500_tickers[:10]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90f2aa01",
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = get_sp500_tickers()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0874b913",
   "metadata": {},
   "source": [
    "## Step 1: Fetch Price Data for All Tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "385c1125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching S&P 500 ticker list…\n",
      "Got 503 tickers. Date range: 2004-01-01 → 2024-12-31\n",
      "  Downloading tickers MMM … ADSK …\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  50 of 50 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading tickers ADP … CVX …\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  50 of 50 completed\n",
      "[                       0%                       ]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading tickers CMG … D …\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  50 of 50 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading tickers DPZ … FTNT …\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  50 of 50 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading tickers FTV … INTC …\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  50 of 50 completed\n",
      "\n",
      "1 Failed download:\n",
      "['IR']: Timeout('Failed to perform, curl: (28) Connection timed out after 10005 milliseconds. See https://curl.se/libcurl/c/libcurl-errors.html first for more details.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading tickers ICE … MKTX …\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  50 of 50 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading tickers MAR … NXPI …\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  50 of 50 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading tickers ORLY … RVTY …\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  50 of 50 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading tickers ROK … TDG …\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  50 of 50 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading tickers TRV … YUM …\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  50 of 50 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading tickers ZBRA … ZTS …\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  3 of 3 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Price download complete. Raw shape: (5284, 3018)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th colspan=\"6\" halign=\"left\">AMD</th>\n",
       "      <th colspan=\"4\" halign=\"left\">ADBE</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"4\" halign=\"left\">ZTS</th>\n",
       "      <th colspan=\"6\" halign=\"left\">ZBRA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Price</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>...</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2004-01-02</th>\n",
       "      <td>15.10</td>\n",
       "      <td>15.11</td>\n",
       "      <td>14.77</td>\n",
       "      <td>14.86</td>\n",
       "      <td>14.86</td>\n",
       "      <td>8220700</td>\n",
       "      <td>19.820000</td>\n",
       "      <td>19.850000</td>\n",
       "      <td>19.434999</td>\n",
       "      <td>19.549999</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.126667</td>\n",
       "      <td>44.186668</td>\n",
       "      <td>43.406666</td>\n",
       "      <td>43.586666</td>\n",
       "      <td>43.586666</td>\n",
       "      <td>339900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-05</th>\n",
       "      <td>15.05</td>\n",
       "      <td>15.27</td>\n",
       "      <td>15.01</td>\n",
       "      <td>15.20</td>\n",
       "      <td>15.20</td>\n",
       "      <td>9156000</td>\n",
       "      <td>19.650000</td>\n",
       "      <td>19.990000</td>\n",
       "      <td>19.230000</td>\n",
       "      <td>19.900000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.486668</td>\n",
       "      <td>44.180000</td>\n",
       "      <td>43.393333</td>\n",
       "      <td>43.666668</td>\n",
       "      <td>43.666668</td>\n",
       "      <td>640950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-06</th>\n",
       "      <td>15.21</td>\n",
       "      <td>15.82</td>\n",
       "      <td>15.05</td>\n",
       "      <td>15.61</td>\n",
       "      <td>15.61</td>\n",
       "      <td>14592200</td>\n",
       "      <td>19.920000</td>\n",
       "      <td>19.990000</td>\n",
       "      <td>19.570000</td>\n",
       "      <td>19.920000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.566666</td>\n",
       "      <td>43.886665</td>\n",
       "      <td>43.366669</td>\n",
       "      <td>43.766666</td>\n",
       "      <td>43.766666</td>\n",
       "      <td>311700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-07</th>\n",
       "      <td>15.78</td>\n",
       "      <td>15.99</td>\n",
       "      <td>15.49</td>\n",
       "      <td>15.66</td>\n",
       "      <td>15.66</td>\n",
       "      <td>15329300</td>\n",
       "      <td>19.719999</td>\n",
       "      <td>19.850000</td>\n",
       "      <td>19.555000</td>\n",
       "      <td>19.719999</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.633331</td>\n",
       "      <td>44.653332</td>\n",
       "      <td>43.500000</td>\n",
       "      <td>44.500000</td>\n",
       "      <td>44.500000</td>\n",
       "      <td>495150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-08</th>\n",
       "      <td>15.95</td>\n",
       "      <td>16.00</td>\n",
       "      <td>15.59</td>\n",
       "      <td>15.93</td>\n",
       "      <td>15.93</td>\n",
       "      <td>11764600</td>\n",
       "      <td>19.705000</td>\n",
       "      <td>19.940001</td>\n",
       "      <td>18.950001</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.939999</td>\n",
       "      <td>45.246666</td>\n",
       "      <td>44.133331</td>\n",
       "      <td>44.599998</td>\n",
       "      <td>44.599998</td>\n",
       "      <td>290850</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3018 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Ticker        AMD                                                ADBE  \\\n",
       "Price        Open   High    Low  Close Adj Close    Volume       Open   \n",
       "Date                                                                    \n",
       "2004-01-02  15.10  15.11  14.77  14.86     14.86   8220700  19.820000   \n",
       "2004-01-05  15.05  15.27  15.01  15.20     15.20   9156000  19.650000   \n",
       "2004-01-06  15.21  15.82  15.05  15.61     15.61  14592200  19.920000   \n",
       "2004-01-07  15.78  15.99  15.49  15.66     15.66  15329300  19.719999   \n",
       "2004-01-08  15.95  16.00  15.59  15.93     15.93  11764600  19.705000   \n",
       "\n",
       "Ticker                                       ... ZTS                         \\\n",
       "Price            High        Low      Close  ... Low Close Adj Close Volume   \n",
       "Date                                         ...                              \n",
       "2004-01-02  19.850000  19.434999  19.549999  ... NaN   NaN       NaN    NaN   \n",
       "2004-01-05  19.990000  19.230000  19.900000  ... NaN   NaN       NaN    NaN   \n",
       "2004-01-06  19.990000  19.570000  19.920000  ... NaN   NaN       NaN    NaN   \n",
       "2004-01-07  19.850000  19.555000  19.719999  ... NaN   NaN       NaN    NaN   \n",
       "2004-01-08  19.940001  18.950001  19.000000  ... NaN   NaN       NaN    NaN   \n",
       "\n",
       "Ticker           ZBRA                                                      \n",
       "Price            Open       High        Low      Close  Adj Close  Volume  \n",
       "Date                                                                       \n",
       "2004-01-02  44.126667  44.186668  43.406666  43.586666  43.586666  339900  \n",
       "2004-01-05  43.486668  44.180000  43.393333  43.666668  43.666668  640950  \n",
       "2004-01-06  43.566666  43.886665  43.366669  43.766666  43.766666  311700  \n",
       "2004-01-07  43.633331  44.653332  43.500000  44.500000  44.500000  495150  \n",
       "2004-01-08  44.939999  45.246666  44.133331  44.599998  44.599998  290850  \n",
       "\n",
       "[5 rows x 3018 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ── Step 1: Fetch price data for the entire S&P 500 ───────────\n",
    "print(\"Fetching S&P 500 ticker list…\")\n",
    "tickers = get_sp500_tickers()\n",
    "print(f\"Got {len(tickers)} tickers. Date range: {start_date} → {end_date}\")\n",
    "\n",
    "# batch size to avoid timeouts / throttling\n",
    "batch_size = 50\n",
    "chunks = [tickers[i:i+batch_size] for i in range(0, len(tickers), batch_size)]\n",
    "\n",
    "frames = []\n",
    "for chunk in chunks:\n",
    "    print(f\"  Downloading tickers {chunk[0]} … {chunk[-1]} …\")\n",
    "    df_chunk = yf.download(\n",
    "        chunk,\n",
    "        start=start_date,\n",
    "        end=end_date,\n",
    "        group_by=\"ticker\",\n",
    "        auto_adjust=False,\n",
    "        threads=True\n",
    "    )\n",
    "    frames.append(df_chunk)\n",
    "\n",
    "# concatenate all batches side-by-side\n",
    "raw = pd.concat(frames, axis=1)\n",
    "\n",
    "# drop rows where *all* tickers missed (e.g. holidays)\n",
    "raw.dropna(how=\"all\", inplace=True)\n",
    "\n",
    "print(\"✅ Price download complete. Raw shape:\", raw.shape)\n",
    "display(raw.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157a4036",
   "metadata": {},
   "source": [
    "## Step 2: Build Unified Event Dates Table (Earnings Only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69c011f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Gathering earnings for MMM…\n",
      "  Gathering earnings for AOS…\n",
      "  Gathering earnings for ABT…\n",
      "  Gathering earnings for ABBV…\n",
      "  Gathering earnings for ACN…\n",
      "  Gathering earnings for ADBE…\n",
      "  Gathering earnings for AMD…\n",
      "  Gathering earnings for AES…\n",
      "  Gathering earnings for AFL…\n",
      "  Gathering earnings for A…\n",
      "  Gathering earnings for APD…\n",
      "  Gathering earnings for ABNB…\n",
      "  Gathering earnings for AKAM…\n",
      "  Gathering earnings for ALB…\n",
      "  Gathering earnings for ARE…\n",
      "  Gathering earnings for ALGN…\n",
      "  Gathering earnings for ALLE…\n",
      "  Gathering earnings for LNT…\n",
      "  Gathering earnings for ALL…\n",
      "  Gathering earnings for GOOGL…\n",
      "  Gathering earnings for GOOG…\n",
      "  Gathering earnings for MO…\n",
      "  Gathering earnings for AMZN…\n",
      "  Gathering earnings for AMCR…\n",
      "  Gathering earnings for AEE…\n",
      "  Gathering earnings for AEP…\n",
      "  Gathering earnings for AXP…\n",
      "  Gathering earnings for AIG…\n",
      "  Gathering earnings for AMT…\n",
      "  Gathering earnings for AWK…\n",
      "  Gathering earnings for AMP…\n",
      "  Gathering earnings for AME…\n",
      "  Gathering earnings for AMGN…\n",
      "  Gathering earnings for APH…\n",
      "  Gathering earnings for ADI…\n",
      "  Gathering earnings for ANSS…\n",
      "  Gathering earnings for AON…\n",
      "  Gathering earnings for APA…\n",
      "  Gathering earnings for APO…\n",
      "  Gathering earnings for AAPL…\n",
      "  Gathering earnings for AMAT…\n",
      "  Gathering earnings for APTV…\n",
      "  Gathering earnings for ACGL…\n",
      "  Gathering earnings for ADM…\n",
      "  Gathering earnings for ANET…\n",
      "  Gathering earnings for AJG…\n",
      "  Gathering earnings for AIZ…\n",
      "  Gathering earnings for T…\n",
      "  Gathering earnings for ATO…\n",
      "  Gathering earnings for ADSK…\n",
      "  Gathering earnings for ADP…\n",
      "  Gathering earnings for AZO…\n",
      "  Gathering earnings for AVB…\n",
      "  Gathering earnings for AVY…\n",
      "  Gathering earnings for AXON…\n",
      "  Gathering earnings for BKR…\n",
      "  Gathering earnings for BALL…\n",
      "  Gathering earnings for BAC…\n",
      "  Gathering earnings for BAX…\n",
      "  Gathering earnings for BDX…\n",
      "  Gathering earnings for BRK-B…\n",
      "  Gathering earnings for BBY…\n",
      "  Gathering earnings for TECH…\n",
      "  Gathering earnings for BIIB…\n",
      "  Gathering earnings for BLK…\n",
      "  Gathering earnings for BX…\n",
      "  Gathering earnings for BK…\n",
      "  Gathering earnings for BA…\n",
      "  Gathering earnings for BKNG…\n",
      "  Gathering earnings for BSX…\n",
      "  Gathering earnings for BMY…\n",
      "  Gathering earnings for AVGO…\n",
      "  Gathering earnings for BR…\n",
      "  Gathering earnings for BRO…\n",
      "  Gathering earnings for BF-B…\n",
      "  Gathering earnings for BLDR…\n",
      "  Gathering earnings for BG…\n",
      "  Gathering earnings for BXP…\n",
      "  Gathering earnings for CHRW…\n",
      "  Gathering earnings for CDNS…\n",
      "  Gathering earnings for CZR…\n",
      "  Gathering earnings for CPT…\n",
      "  Gathering earnings for CPB…\n",
      "  Gathering earnings for COF…\n",
      "  Gathering earnings for CAH…\n",
      "  Gathering earnings for KMX…\n",
      "  Gathering earnings for CCL…\n",
      "  Gathering earnings for CARR…\n",
      "  Gathering earnings for CAT…\n",
      "  Gathering earnings for CBOE…\n",
      "  Gathering earnings for CBRE…\n",
      "  Gathering earnings for CDW…\n",
      "  Gathering earnings for COR…\n",
      "  Gathering earnings for CNC…\n",
      "  Gathering earnings for CNP…\n",
      "  Gathering earnings for CF…\n",
      "  Gathering earnings for CRL…\n",
      "  Gathering earnings for SCHW…\n",
      "  Gathering earnings for CHTR…\n",
      "  Gathering earnings for CVX…\n",
      "  Gathering earnings for CMG…\n",
      "  Gathering earnings for CB…\n",
      "  Gathering earnings for CHD…\n",
      "  Gathering earnings for CI…\n",
      "  Gathering earnings for CINF…\n",
      "  Gathering earnings for CTAS…\n",
      "  Gathering earnings for CSCO…\n",
      "  Gathering earnings for C…\n",
      "  Gathering earnings for CFG…\n",
      "  Gathering earnings for CLX…\n",
      "  Gathering earnings for CME…\n",
      "  Gathering earnings for CMS…\n",
      "  Gathering earnings for KO…\n",
      "  Gathering earnings for CTSH…\n",
      "  Gathering earnings for COIN…\n",
      "  Gathering earnings for CL…\n",
      "  Gathering earnings for CMCSA…\n",
      "  Gathering earnings for CAG…\n",
      "  Gathering earnings for COP…\n",
      "  Gathering earnings for ED…\n",
      "  Gathering earnings for STZ…\n",
      "  Gathering earnings for CEG…\n",
      "  Gathering earnings for COO…\n",
      "  Gathering earnings for CPRT…\n",
      "  Gathering earnings for GLW…\n",
      "  Gathering earnings for CPAY…\n",
      "  Gathering earnings for CTVA…\n",
      "  Gathering earnings for CSGP…\n",
      "  Gathering earnings for COST…\n",
      "  Gathering earnings for CTRA…\n",
      "  Gathering earnings for CRWD…\n",
      "  Gathering earnings for CCI…\n",
      "  Gathering earnings for CSX…\n",
      "  Gathering earnings for CMI…\n",
      "  Gathering earnings for CVS…\n",
      "  Gathering earnings for DHR…\n",
      "  Gathering earnings for DRI…\n",
      "  Gathering earnings for DVA…\n",
      "  Gathering earnings for DAY…\n",
      "  Gathering earnings for DECK…\n",
      "  Gathering earnings for DE…\n",
      "  Gathering earnings for DELL…\n",
      "  Gathering earnings for DAL…\n",
      "  Gathering earnings for DVN…\n",
      "  Gathering earnings for DXCM…\n",
      "  Gathering earnings for FANG…\n",
      "  Gathering earnings for DLR…\n",
      "  Gathering earnings for DG…\n",
      "  Gathering earnings for DLTR…\n",
      "  Gathering earnings for D…\n",
      "  Gathering earnings for DPZ…\n",
      "  Gathering earnings for DASH…\n",
      "  Gathering earnings for DOV…\n",
      "  Gathering earnings for DOW…\n",
      "  Gathering earnings for DHI…\n",
      "  Gathering earnings for DTE…\n",
      "  Gathering earnings for DUK…\n",
      "  Gathering earnings for DD…\n",
      "  Gathering earnings for EMN…\n",
      "  Gathering earnings for ETN…\n",
      "  Gathering earnings for EBAY…\n",
      "  Gathering earnings for ECL…\n",
      "  Gathering earnings for EIX…\n",
      "  Gathering earnings for EW…\n",
      "  Gathering earnings for EA…\n",
      "  Gathering earnings for ELV…\n",
      "  Gathering earnings for EMR…\n",
      "  Gathering earnings for ENPH…\n",
      "  Gathering earnings for ETR…\n",
      "  Gathering earnings for EOG…\n",
      "  Gathering earnings for EPAM…\n",
      "  Gathering earnings for EQT…\n",
      "  Gathering earnings for EFX…\n",
      "  Gathering earnings for EQIX…\n",
      "  Gathering earnings for EQR…\n",
      "  Gathering earnings for ERIE…\n",
      "  Gathering earnings for ESS…\n",
      "  Gathering earnings for EL…\n",
      "  Gathering earnings for EG…\n",
      "  Gathering earnings for EVRG…\n",
      "  Gathering earnings for ES…\n",
      "  Gathering earnings for EXC…\n",
      "  Gathering earnings for EXE…\n",
      "  Gathering earnings for EXPE…\n",
      "  Gathering earnings for EXPD…\n",
      "  Gathering earnings for EXR…\n",
      "  Gathering earnings for XOM…\n",
      "  Gathering earnings for FFIV…\n",
      "  Gathering earnings for FDS…\n",
      "  Gathering earnings for FICO…\n",
      "  Gathering earnings for FAST…\n",
      "  Gathering earnings for FRT…\n",
      "  Gathering earnings for FDX…\n",
      "  Gathering earnings for FIS…\n",
      "  Gathering earnings for FITB…\n",
      "  Gathering earnings for FSLR…\n",
      "  Gathering earnings for FE…\n",
      "  Gathering earnings for FI…\n",
      "  Gathering earnings for F…\n",
      "  Gathering earnings for FTNT…\n",
      "  Gathering earnings for FTV…\n",
      "  Gathering earnings for FOXA…\n",
      "  Gathering earnings for FOX…\n",
      "  Gathering earnings for BEN…\n",
      "  Gathering earnings for FCX…\n",
      "  Gathering earnings for GRMN…\n",
      "  Gathering earnings for IT…\n",
      "  Gathering earnings for GE…\n",
      "  Gathering earnings for GEHC…\n",
      "  Gathering earnings for GEV…\n",
      "  Gathering earnings for GEN…\n",
      "  Gathering earnings for GNRC…\n",
      "  Gathering earnings for GD…\n",
      "  Gathering earnings for GIS…\n",
      "  Gathering earnings for GM…\n",
      "  Gathering earnings for GPC…\n",
      "  Gathering earnings for GILD…\n",
      "  Gathering earnings for GPN…\n",
      "  Gathering earnings for GL…\n",
      "  Gathering earnings for GDDY…\n",
      "  Gathering earnings for GS…\n",
      "  Gathering earnings for HAL…\n",
      "  Gathering earnings for HIG…\n",
      "  Gathering earnings for HAS…\n",
      "  Gathering earnings for HCA…\n",
      "  Gathering earnings for DOC…\n",
      "  Gathering earnings for HSIC…\n",
      "  Gathering earnings for HSY…\n",
      "  Gathering earnings for HES…\n",
      "  Gathering earnings for HPE…\n",
      "  Gathering earnings for HLT…\n",
      "  Gathering earnings for HOLX…\n",
      "  Gathering earnings for HD…\n",
      "  Gathering earnings for HON…\n",
      "  Gathering earnings for HRL…\n",
      "  Gathering earnings for HST…\n",
      "  Gathering earnings for HWM…\n",
      "  Gathering earnings for HPQ…\n",
      "  Gathering earnings for HUBB…\n",
      "  Gathering earnings for HUM…\n",
      "  Gathering earnings for HBAN…\n",
      "  Gathering earnings for HII…\n",
      "  Gathering earnings for IBM…\n",
      "  Gathering earnings for IEX…\n",
      "  Gathering earnings for IDXX…\n",
      "  Gathering earnings for ITW…\n",
      "  Gathering earnings for INCY…\n",
      "  Gathering earnings for IR…\n",
      "  Gathering earnings for PODD…\n",
      "  Gathering earnings for INTC…\n",
      "  Gathering earnings for ICE…\n",
      "  Gathering earnings for IFF…\n",
      "  Gathering earnings for IP…\n",
      "  Gathering earnings for IPG…\n",
      "  Gathering earnings for INTU…\n",
      "  Gathering earnings for ISRG…\n",
      "  Gathering earnings for IVZ…\n",
      "  Gathering earnings for INVH…\n",
      "  Gathering earnings for IQV…\n",
      "  Gathering earnings for IRM…\n",
      "  Gathering earnings for JBHT…\n",
      "  Gathering earnings for JBL…\n",
      "  Gathering earnings for JKHY…\n",
      "  Gathering earnings for J…\n",
      "  Gathering earnings for JNJ…\n",
      "  Gathering earnings for JCI…\n",
      "  Gathering earnings for JPM…\n",
      "  Gathering earnings for JNPR…\n",
      "  Gathering earnings for K…\n",
      "  Gathering earnings for KVUE…\n",
      "  Gathering earnings for KDP…\n",
      "  Gathering earnings for KEY…\n",
      "  Gathering earnings for KEYS…\n",
      "  Gathering earnings for KMB…\n",
      "  Gathering earnings for KIM…\n",
      "  Gathering earnings for KMI…\n",
      "  Gathering earnings for KKR…\n",
      "  Gathering earnings for KLAC…\n",
      "  Gathering earnings for KHC…\n",
      "  Gathering earnings for KR…\n",
      "  Gathering earnings for LHX…\n",
      "  Gathering earnings for LH…\n",
      "  Gathering earnings for LRCX…\n",
      "  Gathering earnings for LW…\n",
      "  Gathering earnings for LVS…\n",
      "  Gathering earnings for LDOS…\n",
      "  Gathering earnings for LEN…\n",
      "  Gathering earnings for LII…\n",
      "  Gathering earnings for LLY…\n",
      "  Gathering earnings for LIN…\n",
      "  Gathering earnings for LYV…\n",
      "  Gathering earnings for LKQ…\n",
      "  Gathering earnings for LMT…\n",
      "  Gathering earnings for L…\n",
      "  Gathering earnings for LOW…\n",
      "  Gathering earnings for LULU…\n",
      "  Gathering earnings for LYB…\n",
      "  Gathering earnings for MTB…\n",
      "  Gathering earnings for MPC…\n",
      "  Gathering earnings for MKTX…\n",
      "  Gathering earnings for MAR…\n",
      "  Gathering earnings for MMC…\n",
      "  Gathering earnings for MLM…\n",
      "  Gathering earnings for MAS…\n",
      "  Gathering earnings for MA…\n",
      "  Gathering earnings for MTCH…\n",
      "  Gathering earnings for MKC…\n",
      "  Gathering earnings for MCD…\n",
      "  Gathering earnings for MCK…\n",
      "  Gathering earnings for MDT…\n",
      "  Gathering earnings for MRK…\n",
      "  Gathering earnings for META…\n",
      "  Gathering earnings for MET…\n",
      "  Gathering earnings for MTD…\n",
      "  Gathering earnings for MGM…\n",
      "  Gathering earnings for MCHP…\n",
      "  Gathering earnings for MU…\n",
      "  Gathering earnings for MSFT…\n",
      "  Gathering earnings for MAA…\n",
      "  Gathering earnings for MRNA…\n",
      "  Gathering earnings for MHK…\n",
      "  Gathering earnings for MOH…\n",
      "  Gathering earnings for TAP…\n",
      "  Gathering earnings for MDLZ…\n",
      "  Gathering earnings for MPWR…\n",
      "  Gathering earnings for MNST…\n",
      "  Gathering earnings for MCO…\n",
      "  Gathering earnings for MS…\n",
      "  Gathering earnings for MOS…\n",
      "  Gathering earnings for MSI…\n",
      "  Gathering earnings for MSCI…\n",
      "  Gathering earnings for NDAQ…\n",
      "  Gathering earnings for NTAP…\n",
      "  Gathering earnings for NFLX…\n",
      "  Gathering earnings for NEM…\n",
      "  Gathering earnings for NWSA…\n",
      "  Gathering earnings for NWS…\n",
      "  Gathering earnings for NEE…\n",
      "  Gathering earnings for NKE…\n",
      "  Gathering earnings for NI…\n",
      "  Gathering earnings for NDSN…\n",
      "  Gathering earnings for NSC…\n",
      "  Gathering earnings for NTRS…\n",
      "  Gathering earnings for NOC…\n",
      "  Gathering earnings for NCLH…\n",
      "  Gathering earnings for NRG…\n",
      "  Gathering earnings for NUE…\n",
      "  Gathering earnings for NVDA…\n",
      "  Gathering earnings for NVR…\n",
      "  Gathering earnings for NXPI…\n",
      "  Gathering earnings for ORLY…\n",
      "  Gathering earnings for OXY…\n",
      "  Gathering earnings for ODFL…\n",
      "  Gathering earnings for OMC…\n",
      "  Gathering earnings for ON…\n",
      "  Gathering earnings for OKE…\n",
      "  Gathering earnings for ORCL…\n",
      "  Gathering earnings for OTIS…\n",
      "  Gathering earnings for PCAR…\n",
      "  Gathering earnings for PKG…\n",
      "  Gathering earnings for PLTR…\n",
      "  Gathering earnings for PANW…\n",
      "  Gathering earnings for PARA…\n",
      "  Gathering earnings for PH…\n",
      "  Gathering earnings for PAYX…\n",
      "  Gathering earnings for PAYC…\n",
      "  Gathering earnings for PYPL…\n",
      "  Gathering earnings for PNR…\n",
      "  Gathering earnings for PEP…\n",
      "  Gathering earnings for PFE…\n",
      "  Gathering earnings for PCG…\n",
      "  Gathering earnings for PM…\n",
      "  Gathering earnings for PSX…\n",
      "  Gathering earnings for PNW…\n",
      "  Gathering earnings for PNC…\n",
      "  Gathering earnings for POOL…\n",
      "  Gathering earnings for PPG…\n",
      "  Gathering earnings for PPL…\n",
      "  Gathering earnings for PFG…\n",
      "  Gathering earnings for PG…\n",
      "  Gathering earnings for PGR…\n",
      "  Gathering earnings for PLD…\n",
      "  Gathering earnings for PRU…\n",
      "  Gathering earnings for PEG…\n",
      "  Gathering earnings for PTC…\n",
      "  Gathering earnings for PSA…\n",
      "  Gathering earnings for PHM…\n",
      "  Gathering earnings for PWR…\n",
      "  Gathering earnings for QCOM…\n",
      "  Gathering earnings for DGX…\n",
      "  Gathering earnings for RL…\n",
      "  Gathering earnings for RJF…\n",
      "  Gathering earnings for RTX…\n",
      "  Gathering earnings for O…\n",
      "  Gathering earnings for REG…\n",
      "  Gathering earnings for REGN…\n",
      "  Gathering earnings for RF…\n",
      "  Gathering earnings for RSG…\n",
      "  Gathering earnings for RMD…\n",
      "  Gathering earnings for RVTY…\n",
      "  Gathering earnings for ROK…\n",
      "  Gathering earnings for ROL…\n",
      "  Gathering earnings for ROP…\n",
      "  Gathering earnings for ROST…\n",
      "  Gathering earnings for RCL…\n",
      "  Gathering earnings for SPGI…\n",
      "  Gathering earnings for CRM…\n",
      "  Gathering earnings for SBAC…\n",
      "  Gathering earnings for SLB…\n",
      "  Gathering earnings for STX…\n",
      "  Gathering earnings for SRE…\n",
      "  Gathering earnings for NOW…\n",
      "  Gathering earnings for SHW…\n",
      "  Gathering earnings for SPG…\n",
      "  Gathering earnings for SWKS…\n",
      "  Gathering earnings for SJM…\n",
      "  Gathering earnings for SW…\n",
      "  Gathering earnings for SNA…\n",
      "  Gathering earnings for SOLV…\n",
      "  Gathering earnings for SO…\n",
      "  Gathering earnings for LUV…\n",
      "  Gathering earnings for SWK…\n",
      "  Gathering earnings for SBUX…\n",
      "  Gathering earnings for STT…\n",
      "  Gathering earnings for STLD…\n",
      "  Gathering earnings for STE…\n",
      "  Gathering earnings for SYK…\n",
      "  Gathering earnings for SMCI…\n",
      "  Gathering earnings for SYF…\n",
      "  Gathering earnings for SNPS…\n",
      "  Gathering earnings for SYY…\n",
      "  Gathering earnings for TMUS…\n",
      "  Gathering earnings for TROW…\n",
      "  Gathering earnings for TTWO…\n",
      "  Gathering earnings for TPR…\n",
      "  Gathering earnings for TRGP…\n",
      "  Gathering earnings for TGT…\n",
      "  Gathering earnings for TEL…\n",
      "  Gathering earnings for TDY…\n",
      "  Gathering earnings for TER…\n",
      "  Gathering earnings for TSLA…\n",
      "  Gathering earnings for TXN…\n",
      "  Gathering earnings for TPL…\n",
      "  Gathering earnings for TXT…\n",
      "  Gathering earnings for TMO…\n",
      "  Gathering earnings for TJX…\n",
      "  Gathering earnings for TKO…\n",
      "  Gathering earnings for TSCO…\n",
      "  Gathering earnings for TT…\n",
      "  Gathering earnings for TDG…\n",
      "  Gathering earnings for TRV…\n",
      "  Gathering earnings for TRMB…\n",
      "  Gathering earnings for TFC…\n",
      "  Gathering earnings for TYL…\n",
      "  Gathering earnings for TSN…\n",
      "  Gathering earnings for USB…\n",
      "  Gathering earnings for UBER…\n",
      "  Gathering earnings for UDR…\n",
      "  Gathering earnings for ULTA…\n",
      "  Gathering earnings for UNP…\n",
      "  Gathering earnings for UAL…\n",
      "  Gathering earnings for UPS…\n",
      "  Gathering earnings for URI…\n",
      "  Gathering earnings for UNH…\n",
      "  Gathering earnings for UHS…\n",
      "  Gathering earnings for VLO…\n",
      "  Gathering earnings for VTR…\n",
      "  Gathering earnings for VLTO…\n",
      "  Gathering earnings for VRSN…\n",
      "  Gathering earnings for VRSK…\n",
      "  Gathering earnings for VZ…\n",
      "  Gathering earnings for VRTX…\n",
      "  Gathering earnings for VTRS…\n",
      "  Gathering earnings for VICI…\n",
      "  Gathering earnings for V…\n",
      "  Gathering earnings for VST…\n",
      "  Gathering earnings for VMC…\n",
      "  Gathering earnings for WRB…\n",
      "  Gathering earnings for GWW…\n",
      "  Gathering earnings for WAB…\n",
      "  Gathering earnings for WBA…\n",
      "  Gathering earnings for WMT…\n",
      "  Gathering earnings for DIS…\n",
      "  Gathering earnings for WBD…\n",
      "  Gathering earnings for WM…\n",
      "  Gathering earnings for WAT…\n",
      "  Gathering earnings for WEC…\n",
      "  Gathering earnings for WFC…\n",
      "  Gathering earnings for WELL…\n",
      "  Gathering earnings for WST…\n",
      "  Gathering earnings for WDC…\n",
      "  Gathering earnings for WY…\n",
      "  Gathering earnings for WSM…\n",
      "  Gathering earnings for WMB…\n",
      "  Gathering earnings for WTW…\n",
      "  Gathering earnings for WDAY…\n",
      "  Gathering earnings for WYNN…\n",
      "  Gathering earnings for XEL…\n",
      "  Gathering earnings for XYL…\n",
      "  Gathering earnings for YUM…\n",
      "  Gathering earnings for ZBRA…\n",
      "  Gathering earnings for ZBH…\n",
      "  Gathering earnings for ZTS…\n",
      "Total earnings events: 2974\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-07-28</td>\n",
       "      <td>KIM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-08-01</td>\n",
       "      <td>SPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-08-04</td>\n",
       "      <td>FRT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-08-17</td>\n",
       "      <td>AMCR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-10-27</td>\n",
       "      <td>AOS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date Ticker\n",
       "0 2022-07-28    KIM\n",
       "1 2022-08-01    SPG\n",
       "2 2022-08-04    FRT\n",
       "3 2022-08-17   AMCR\n",
       "4 2022-10-27    AOS"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "events = []\n",
    "\n",
    "for t in tickers:\n",
    "    print(f\"  Gathering earnings for {t}…\")\n",
    "    ed = yf.Ticker(t).earnings_dates.reset_index()\n",
    "    ed.columns = [\"Date\",\"Estimate\",\"Reported\",\"Surprise_%\"]\n",
    "    # strip tz, normalize to midnight\n",
    "    ed[\"Date\"] = ed[\"Date\"].dt.tz_localize(None).dt.normalize()\n",
    "    ed[\"Ticker\"] = t\n",
    "    events.append(ed[[\"Date\",\"Ticker\"]])\n",
    "\n",
    "earnings_dates = pd.concat(events, ignore_index=True)\n",
    "# filter to your date window\n",
    "earnings_dates = earnings_dates[\n",
    "    (earnings_dates[\"Date\"]>=pd.to_datetime(start_date)) &\n",
    "    (earnings_dates[\"Date\"]<=pd.to_datetime(end_date))\n",
    "].sort_values([\"Date\",\"Ticker\"]).reset_index(drop=True)\n",
    "\n",
    "print(f\"Total earnings events: {len(earnings_dates)}\")\n",
    "display(earnings_dates.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1dd2256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total earnings events (with Surprise_%): 2974\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Surprise_%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-07-28</td>\n",
       "      <td>KIM</td>\n",
       "      <td>-241.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-08-01</td>\n",
       "      <td>SPG</td>\n",
       "      <td>5.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-08-04</td>\n",
       "      <td>FRT</td>\n",
       "      <td>24.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-08-17</td>\n",
       "      <td>AMCR</td>\n",
       "      <td>2.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-10-27</td>\n",
       "      <td>AOS</td>\n",
       "      <td>-0.31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date Ticker  Surprise_%\n",
       "0 2022-07-28    KIM     -241.35\n",
       "1 2022-08-01    SPG        5.59\n",
       "2 2022-08-04    FRT       24.48\n",
       "3 2022-08-17   AMCR        2.09\n",
       "4 2022-10-27    AOS       -0.31"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 2: Build unified earnings_dates with Surprise_% included\n",
    "events = []\n",
    "for t in tickers:\n",
    "    ed = yf.Ticker(t).earnings_dates.reset_index()\n",
    "    ed.columns = [\"Date\",\"Earnings_Estimate\",\"Reported_Earnings\",\"Surprise_%\"]\n",
    "    # strip tz & normalize\n",
    "    ed[\"Date\"]   = ed[\"Date\"].dt.tz_localize(None).dt.normalize()\n",
    "    ed[\"Ticker\"] = t\n",
    "    # keep Surprise_% so you can join on it later\n",
    "    events.append(ed[[\"Date\",\"Ticker\",\"Surprise_%\"]])\n",
    "\n",
    "earnings_dates = pd.concat(events, ignore_index=True)\n",
    "earnings_dates = earnings_dates[\n",
    "    (earnings_dates[\"Date\"] >= pd.to_datetime(start_date)) &\n",
    "    (earnings_dates[\"Date\"] <= pd.to_datetime(end_date))\n",
    "].sort_values([\"Date\",\"Ticker\"]).reset_index(drop=True)\n",
    "\n",
    "print(f\"Total earnings events (with Surprise_%): {len(earnings_dates)}\")\n",
    "display(earnings_dates.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a292de65",
   "metadata": {},
   "source": [
    "## Step 3: Feature Engineering Per Ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a671c758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Engineering features for MMM…\n",
      "  Engineering features for AOS…\n",
      "  Engineering features for ABT…\n",
      "  Engineering features for ABBV…\n",
      "  Engineering features for ACN…\n",
      "  Engineering features for ADBE…\n",
      "  Engineering features for AMD…\n",
      "  Engineering features for AES…\n",
      "  Engineering features for AFL…\n",
      "  Engineering features for A…\n",
      "  Engineering features for APD…\n",
      "  Engineering features for ABNB…\n",
      "  Engineering features for AKAM…\n",
      "  Engineering features for ALB…\n",
      "  Engineering features for ARE…\n",
      "  Engineering features for ALGN…\n",
      "  Engineering features for ALLE…\n",
      "  Engineering features for LNT…\n",
      "  Engineering features for ALL…\n",
      "  Engineering features for GOOGL…\n",
      "  Engineering features for GOOG…\n",
      "  Engineering features for MO…\n",
      "  Engineering features for AMZN…\n",
      "  Engineering features for AMCR…\n",
      "  Engineering features for AEE…\n",
      "  Engineering features for AEP…\n",
      "  Engineering features for AXP…\n",
      "  Engineering features for AIG…\n",
      "  Engineering features for AMT…\n",
      "  Engineering features for AWK…\n",
      "  Engineering features for AMP…\n",
      "  Engineering features for AME…\n",
      "  Engineering features for AMGN…\n",
      "  Engineering features for APH…\n",
      "  Engineering features for ADI…\n",
      "  Engineering features for ANSS…\n",
      "  Engineering features for AON…\n",
      "  Engineering features for APA…\n",
      "  Engineering features for APO…\n",
      "  Engineering features for AAPL…\n",
      "  Engineering features for AMAT…\n",
      "  Engineering features for APTV…\n",
      "  Engineering features for ACGL…\n",
      "  Engineering features for ADM…\n",
      "  Engineering features for ANET…\n",
      "  Engineering features for AJG…\n",
      "  Engineering features for AIZ…\n",
      "  Engineering features for T…\n",
      "  Engineering features for ATO…\n",
      "  Engineering features for ADSK…\n",
      "  Engineering features for ADP…\n",
      "  Engineering features for AZO…\n",
      "  Engineering features for AVB…\n",
      "  Engineering features for AVY…\n",
      "  Engineering features for AXON…\n",
      "  Engineering features for BKR…\n",
      "  Engineering features for BALL…\n",
      "  Engineering features for BAC…\n",
      "  Engineering features for BAX…\n",
      "  Engineering features for BDX…\n",
      "  Engineering features for BRK-B…\n",
      "  Engineering features for BBY…\n",
      "  Engineering features for TECH…\n",
      "  Engineering features for BIIB…\n",
      "  Engineering features for BLK…\n",
      "  Engineering features for BX…\n",
      "  Engineering features for BK…\n",
      "  Engineering features for BA…\n",
      "  Engineering features for BKNG…\n",
      "  Engineering features for BSX…\n",
      "  Engineering features for BMY…\n",
      "  Engineering features for AVGO…\n",
      "  Engineering features for BR…\n",
      "  Engineering features for BRO…\n",
      "  Engineering features for BF-B…\n",
      "  Engineering features for BLDR…\n",
      "  Engineering features for BG…\n",
      "  Engineering features for BXP…\n",
      "  Engineering features for CHRW…\n",
      "  Engineering features for CDNS…\n",
      "  Engineering features for CZR…\n",
      "  Engineering features for CPT…\n",
      "  Engineering features for CPB…\n",
      "  Engineering features for COF…\n",
      "  Engineering features for CAH…\n",
      "  Engineering features for KMX…\n",
      "  Engineering features for CCL…\n",
      "  Engineering features for CARR…\n",
      "  Engineering features for CAT…\n",
      "  Engineering features for CBOE…\n",
      "  Engineering features for CBRE…\n",
      "  Engineering features for CDW…\n",
      "  Engineering features for COR…\n",
      "  Engineering features for CNC…\n",
      "  Engineering features for CNP…\n",
      "  Engineering features for CF…\n",
      "  Engineering features for CRL…\n",
      "  Engineering features for SCHW…\n",
      "  Engineering features for CHTR…\n",
      "  Engineering features for CVX…\n",
      "  Engineering features for CMG…\n",
      "  Engineering features for CB…\n",
      "  Engineering features for CHD…\n",
      "  Engineering features for CI…\n",
      "  Engineering features for CINF…\n",
      "  Engineering features for CTAS…\n",
      "  Engineering features for CSCO…\n",
      "  Engineering features for C…\n",
      "  Engineering features for CFG…\n",
      "  Engineering features for CLX…\n",
      "  Engineering features for CME…\n",
      "  Engineering features for CMS…\n",
      "  Engineering features for KO…\n",
      "  Engineering features for CTSH…\n",
      "  Engineering features for COIN…\n",
      "  Engineering features for CL…\n",
      "  Engineering features for CMCSA…\n",
      "  Engineering features for CAG…\n",
      "  Engineering features for COP…\n",
      "  Engineering features for ED…\n",
      "  Engineering features for STZ…\n",
      "  Engineering features for CEG…\n",
      "  Engineering features for COO…\n",
      "  Engineering features for CPRT…\n",
      "  Engineering features for GLW…\n",
      "  Engineering features for CPAY…\n",
      "  Engineering features for CTVA…\n",
      "  Engineering features for CSGP…\n",
      "  Engineering features for COST…\n",
      "  Engineering features for CTRA…\n",
      "  Engineering features for CRWD…\n",
      "  Engineering features for CCI…\n",
      "  Engineering features for CSX…\n",
      "  Engineering features for CMI…\n",
      "  Engineering features for CVS…\n",
      "  Engineering features for DHR…\n",
      "  Engineering features for DRI…\n",
      "  Engineering features for DVA…\n",
      "  Engineering features for DAY…\n",
      "  Engineering features for DECK…\n",
      "  Engineering features for DE…\n",
      "  Engineering features for DELL…\n",
      "  Engineering features for DAL…\n",
      "  Engineering features for DVN…\n",
      "  Engineering features for DXCM…\n",
      "  Engineering features for FANG…\n",
      "  Engineering features for DLR…\n",
      "  Engineering features for DG…\n",
      "  Engineering features for DLTR…\n",
      "  Engineering features for D…\n",
      "  Engineering features for DPZ…\n",
      "  Engineering features for DASH…\n",
      "  Engineering features for DOV…\n",
      "  Engineering features for DOW…\n",
      "  Engineering features for DHI…\n",
      "  Engineering features for DTE…\n",
      "  Engineering features for DUK…\n",
      "  Engineering features for DD…\n",
      "  Engineering features for EMN…\n",
      "  Engineering features for ETN…\n",
      "  Engineering features for EBAY…\n",
      "  Engineering features for ECL…\n",
      "  Engineering features for EIX…\n",
      "  Engineering features for EW…\n",
      "  Engineering features for EA…\n",
      "  Engineering features for ELV…\n",
      "  Engineering features for EMR…\n",
      "  Engineering features for ENPH…\n",
      "  Engineering features for ETR…\n",
      "  Engineering features for EOG…\n",
      "  Engineering features for EPAM…\n",
      "  Engineering features for EQT…\n",
      "  Engineering features for EFX…\n",
      "  Engineering features for EQIX…\n",
      "  Engineering features for EQR…\n",
      "  Engineering features for ERIE…\n",
      "  Engineering features for ESS…\n",
      "  Engineering features for EL…\n",
      "  Engineering features for EG…\n",
      "  Engineering features for EVRG…\n",
      "  Engineering features for ES…\n",
      "  Engineering features for EXC…\n",
      "  Engineering features for EXE…\n",
      "  Engineering features for EXPE…\n",
      "  Engineering features for EXPD…\n",
      "  Engineering features for EXR…\n",
      "  Engineering features for XOM…\n",
      "  Engineering features for FFIV…\n",
      "  Engineering features for FDS…\n",
      "  Engineering features for FICO…\n",
      "  Engineering features for FAST…\n",
      "  Engineering features for FRT…\n",
      "  Engineering features for FDX…\n",
      "  Engineering features for FIS…\n",
      "  Engineering features for FITB…\n",
      "  Engineering features for FSLR…\n",
      "  Engineering features for FE…\n",
      "  Engineering features for FI…\n",
      "  Engineering features for F…\n",
      "  Engineering features for FTNT…\n",
      "  Engineering features for FTV…\n",
      "  Engineering features for FOXA…\n",
      "  Engineering features for FOX…\n",
      "  Engineering features for BEN…\n",
      "  Engineering features for FCX…\n",
      "  Engineering features for GRMN…\n",
      "  Engineering features for IT…\n",
      "  Engineering features for GE…\n",
      "  Engineering features for GEHC…\n",
      "  Engineering features for GEV…\n",
      "  Engineering features for GEN…\n",
      "  Engineering features for GNRC…\n",
      "  Engineering features for GD…\n",
      "  Engineering features for GIS…\n",
      "  Engineering features for GM…\n",
      "  Engineering features for GPC…\n",
      "  Engineering features for GILD…\n",
      "  Engineering features for GPN…\n",
      "  Engineering features for GL…\n",
      "  Engineering features for GDDY…\n",
      "  Engineering features for GS…\n",
      "  Engineering features for HAL…\n",
      "  Engineering features for HIG…\n",
      "  Engineering features for HAS…\n",
      "  Engineering features for HCA…\n",
      "  Engineering features for DOC…\n",
      "  Engineering features for HSIC…\n",
      "  Engineering features for HSY…\n",
      "  Engineering features for HES…\n",
      "  Engineering features for HPE…\n",
      "  Engineering features for HLT…\n",
      "  Engineering features for HOLX…\n",
      "  Engineering features for HD…\n",
      "  Engineering features for HON…\n",
      "  Engineering features for HRL…\n",
      "  Engineering features for HST…\n",
      "  Engineering features for HWM…\n",
      "  Engineering features for HPQ…\n",
      "  Engineering features for HUBB…\n",
      "  Engineering features for HUM…\n",
      "  Engineering features for HBAN…\n",
      "  Engineering features for HII…\n",
      "  Engineering features for IBM…\n",
      "  Engineering features for IEX…\n",
      "  Engineering features for IDXX…\n",
      "  Engineering features for ITW…\n",
      "  Engineering features for INCY…\n",
      "  Engineering features for IR…\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "attempt to get argmax of an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m df_t\u001b[38;5;241m.\u001b[39mdropna(subset\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClose\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVolume\u001b[39m\u001b[38;5;124m\"\u001b[39m], inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# 4) basic features\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m df_t[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturn\u001b[39m\u001b[38;5;124m\"\u001b[39m]      \u001b[38;5;241m=\u001b[39m \u001b[43mdf_t\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mClose\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpct_change\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m df_t[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVolatility\u001b[39m\u001b[38;5;124m\"\u001b[39m]  \u001b[38;5;241m=\u001b[39m df_t[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturn\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mrolling(\u001b[38;5;241m5\u001b[39m)\u001b[38;5;241m.\u001b[39mstd()\n\u001b[0;32m     21\u001b[0m df_t[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRSI\u001b[39m\u001b[38;5;124m\"\u001b[39m]         \u001b[38;5;241m=\u001b[39m RSIIndicator(close\u001b[38;5;241m=\u001b[39mdf_t[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClose\u001b[39m\u001b[38;5;124m\"\u001b[39m], window\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m14\u001b[39m)\u001b[38;5;241m.\u001b[39mrsi()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\generic.py:11704\u001b[0m, in \u001b[0;36mNDFrame.pct_change\u001b[1;34m(self, periods, fill_method, limit, freq, **kwargs)\u001b[0m\n\u001b[0;32m  11702\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, col \u001b[38;5;129;01min\u001b[39;00m cols:\n\u001b[0;32m  11703\u001b[0m     mask \u001b[38;5;241m=\u001b[39m col\u001b[38;5;241m.\u001b[39misna()\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m> 11704\u001b[0m     mask \u001b[38;5;241m=\u001b[39m mask[\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margmax\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m~\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m :]\n\u001b[0;32m  11705\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m  11706\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m  11707\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe default fill_method=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpad\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m  11708\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pct_change is deprecated and will \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  11713\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m  11714\u001b[0m         )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\core\\fromnumeric.py:1229\u001b[0m, in \u001b[0;36margmax\u001b[1;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[0;32m   1142\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1143\u001b[0m \u001b[38;5;124;03mReturns the indices of the maximum values along an axis.\u001b[39;00m\n\u001b[0;32m   1144\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1226\u001b[0m \u001b[38;5;124;03m(2, 1, 4)\u001b[39;00m\n\u001b[0;32m   1227\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1228\u001b[0m kwds \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeepdims\u001b[39m\u001b[38;5;124m'\u001b[39m: keepdims} \u001b[38;5;28;01mif\u001b[39;00m keepdims \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39m_NoValue \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[1;32m-> 1229\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43margmax\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\core\\fromnumeric.py:59\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbound\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "\u001b[1;31mValueError\u001b[0m: attempt to get argmax of an empty sequence"
     ]
    }
   ],
   "source": [
    "feature_list = []\n",
    "\n",
    "for t in tickers:\n",
    "    print(f\"  Engineering features for {t}…\")\n",
    "    df_t = raw[t].copy()  # slice out ticker\n",
    "    \n",
    "    # 1) flatten MultiIndex\n",
    "    if isinstance(df_t.columns, pd.MultiIndex):\n",
    "        df_t.columns = df_t.columns.get_level_values(0)\n",
    "    # 2) drop stray Price\n",
    "    df_t.drop(columns=[c for c in [\"Price\"] if c in df_t], inplace=True)\n",
    "    \n",
    "    # 3) coerce core series\n",
    "    df_t[\"Close\"]  = pd.to_numeric(df_t[\"Close\"],  errors=\"coerce\")\n",
    "    df_t[\"Volume\"] = pd.to_numeric(df_t[\"Volume\"], errors=\"coerce\")\n",
    "    df_t.dropna(subset=[\"Close\",\"Volume\"], inplace=True)\n",
    "    \n",
    "    # 4) basic features\n",
    "    df_t[\"Return\"]      = df_t[\"Close\"].pct_change()\n",
    "    df_t[\"Volatility\"]  = df_t[\"Return\"].rolling(5).std()\n",
    "    df_t[\"RSI\"]         = RSIIndicator(close=df_t[\"Close\"], window=14).rsi()\n",
    "    df_t[\"MA5\"]         = df_t[\"Close\"].rolling(5).mean()\n",
    "    df_t[\"MA10\"]        = df_t[\"Close\"].rolling(10).mean()\n",
    "    df_t[\"MA_ratio\"]    = df_t[\"MA5\"] / df_t[\"MA10\"] - 1\n",
    "    df_t[\"Volume_Avg20\"]= df_t[\"Volume\"].rolling(20).mean()\n",
    "    df_t[\"Volume_Spike\"]= df_t[\"Volume\"] / df_t[\"Volume_Avg20\"] - 1\n",
    "    \n",
    "    # 5) new predictive features\n",
    "    df_t[\"Momentum3\"]   = df_t[\"Close\"].pct_change(3)\n",
    "    atr = AverageTrueRange(high=df_t[\"High\"], low=df_t[\"Low\"], \n",
    "                           close=df_t[\"Close\"], window=14)\n",
    "    df_t[\"ATR14\"]       = atr.average_true_range()\n",
    "    df_t[\"DayOfWeek\"]   = df_t.index.dayofweek\n",
    "    df_t[\"Month\"]       = df_t.index.month\n",
    "\n",
    "    # ——— HERE: merge in Surprise_% from your earnings_dates ———\n",
    "    # slice out only this ticker’s surprises\n",
    "    ed_t = (\n",
    "        earnings_dates\n",
    "        .loc[earnings_dates[\"Ticker\"] == t, [\"Date\",\"Surprise_%\"]]\n",
    "        .set_index(\"Date\")\n",
    "    )\n",
    "    # align on the same dates, left‐join so non-event days get NaN\n",
    "    df_t = df_t.join(ed_t, how=\"left\")\n",
    "    # fill non‐events with zero surprise\n",
    "    df_t[\"Surprise_%\"] = df_t[\"Surprise_%\"].fillna(0)\n",
    "    \n",
    "    # 6) drop NaNs from rolling/pct_change (but keep Surprise_% zeros)\n",
    "    df_t.dropna(subset=[\n",
    "        \"Return\",\"Volatility\",\"RSI\",\"MA5\",\"MA10\",\"MA_ratio\",\n",
    "        \"Volume_Avg20\",\"Volume_Spike\",\"Momentum3\",\"ATR14\"\n",
    "    ], inplace=True)\n",
    "    \n",
    "    # 7) select your expanded feature set\n",
    "    keep = [\n",
    "        \"Close\",\"Volume\",\n",
    "        \"Return\",\"Volatility\",\"RSI\",\n",
    "        \"MA5\",\"MA10\",\"MA_ratio\",\n",
    "        \"Volume_Avg20\",\"Volume_Spike\",\n",
    "        \"Momentum3\",\"ATR14\",\n",
    "        \"DayOfWeek\",\"Month\",\n",
    "        \"Surprise_%\"\n",
    "    ]\n",
    "    feats = df_t[keep].copy()\n",
    "    feats[\"Ticker\"] = t\n",
    "    feature_list.append(feats)\n",
    "\n",
    "# concatenate all tickers\n",
    "features_df = pd.concat(feature_list)\n",
    "features_df.index.name = \"Date\"\n",
    "features_df = features_df.sort_index()\n",
    "\n",
    "print(\"Features shape (all tickers):\", features_df.shape)\n",
    "display(features_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10473331",
   "metadata": {},
   "source": [
    "## Step 4: Create Event-Only Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6c1d5548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labeled 2963 events:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-07-28</td>\n",
       "      <td>KIM</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-08-01</td>\n",
       "      <td>SPG</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-08-04</td>\n",
       "      <td>FRT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-08-17</td>\n",
       "      <td>AMCR</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-10-27</td>\n",
       "      <td>AOS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2958</th>\n",
       "      <td>2024-12-19</td>\n",
       "      <td>KMX</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2959</th>\n",
       "      <td>2024-12-19</td>\n",
       "      <td>LW</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2960</th>\n",
       "      <td>2024-12-19</td>\n",
       "      <td>NKE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2961</th>\n",
       "      <td>2024-12-19</td>\n",
       "      <td>PAYX</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2962</th>\n",
       "      <td>2024-12-20</td>\n",
       "      <td>CCL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2963 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date Ticker  Target\n",
       "0    2022-07-28    KIM       1\n",
       "1    2022-08-01    SPG       0\n",
       "2    2022-08-04    FRT       1\n",
       "3    2022-08-17   AMCR       0\n",
       "4    2022-10-27    AOS       1\n",
       "...         ...    ...     ...\n",
       "2958 2024-12-19    KMX       1\n",
       "2959 2024-12-19     LW       0\n",
       "2960 2024-12-19    NKE       0\n",
       "2961 2024-12-19   PAYX       1\n",
       "2962 2024-12-20    CCL       0\n",
       "\n",
       "[2963 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 4: Label creation (target variable) for multi‐ticker MultiIndex\n",
    "\n",
    "def create_labels(event_dates, price_df, horizon=3):\n",
    "    \"\"\"\n",
    "    event_dates: DataFrame with ['Date','Ticker'] columns of pd.Timestamps\n",
    "    price_df:    DataFrame with a MultiIndex (Date, Ticker) and at least a 'Close' column\n",
    "    horizon:     how many trading days ahead to look\n",
    "    \"\"\"\n",
    "    labels = []\n",
    "    # 1) pre‐shift the Close series within each ticker\n",
    "    future_close = price_df['Close'].groupby(level='Ticker').shift(-horizon)\n",
    "    \n",
    "    for _, ev in event_dates.iterrows():\n",
    "        dt, tkr = ev['Date'], ev['Ticker']\n",
    "        key = (dt, tkr)\n",
    "        # 2) skip if that (Date, Ticker) combo isn't in your features\n",
    "        if key not in price_df.index:\n",
    "            continue\n",
    "        \n",
    "        past = price_df.at[key, 'Close']\n",
    "        fut  = future_close.at[key]\n",
    "        # 3) skip if we ran off the end\n",
    "        if pd.isna(fut):\n",
    "            continue\n",
    "        \n",
    "        ret = (fut - past) / past\n",
    "        labels.append({\n",
    "          'Date':   dt,\n",
    "          'Ticker': tkr,\n",
    "          'Target': int(ret > 0)\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(labels)\n",
    "\n",
    "\n",
    "# — how to call it —\n",
    "# make sure features_df is a MultiIndexed DF: index names must be ['Date','Ticker']\n",
    "features_df = features_df.reset_index().set_index(['Date','Ticker'])\n",
    "\n",
    "labels_df = create_labels(earnings_dates, features_df, horizon=horizon)\n",
    "print(f\"Labeled {len(labels_df)} events:\")\n",
    "display(labels_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b05144",
   "metadata": {},
   "source": [
    "## Step 5: Merge features & labels for multi-ticker dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "84a4caf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final dataset shape: (2963, 17)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Return</th>\n",
       "      <th>Volatility</th>\n",
       "      <th>RSI</th>\n",
       "      <th>MA5</th>\n",
       "      <th>MA10</th>\n",
       "      <th>MA_ratio</th>\n",
       "      <th>Volume_Avg20</th>\n",
       "      <th>Volume_Spike</th>\n",
       "      <th>Momentum3</th>\n",
       "      <th>ATR14</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Month</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-07-28</td>\n",
       "      <td>KIM</td>\n",
       "      <td>21.860001</td>\n",
       "      <td>4028800.0</td>\n",
       "      <td>0.016744</td>\n",
       "      <td>0.013179</td>\n",
       "      <td>62.512911</td>\n",
       "      <td>21.498</td>\n",
       "      <td>21.180000</td>\n",
       "      <td>0.015014</td>\n",
       "      <td>3674420.0</td>\n",
       "      <td>0.096445</td>\n",
       "      <td>0.016272</td>\n",
       "      <td>0.522246</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-08-01</td>\n",
       "      <td>SPG</td>\n",
       "      <td>108.629997</td>\n",
       "      <td>1650100.0</td>\n",
       "      <td>-0.000092</td>\n",
       "      <td>0.017185</td>\n",
       "      <td>65.657759</td>\n",
       "      <td>106.286</td>\n",
       "      <td>104.909999</td>\n",
       "      <td>0.013116</td>\n",
       "      <td>1648115.0</td>\n",
       "      <td>0.001204</td>\n",
       "      <td>0.043315</td>\n",
       "      <td>2.614542</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-08-04</td>\n",
       "      <td>FRT</td>\n",
       "      <td>105.040001</td>\n",
       "      <td>797300.0</td>\n",
       "      <td>0.008352</td>\n",
       "      <td>0.009903</td>\n",
       "      <td>59.129102</td>\n",
       "      <td>104.944</td>\n",
       "      <td>103.873000</td>\n",
       "      <td>0.010311</td>\n",
       "      <td>644255.0</td>\n",
       "      <td>0.237553</td>\n",
       "      <td>-0.007090</td>\n",
       "      <td>2.419999</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-08-17</td>\n",
       "      <td>AMCR</td>\n",
       "      <td>13.010000</td>\n",
       "      <td>8882400.0</td>\n",
       "      <td>-0.021068</td>\n",
       "      <td>0.017779</td>\n",
       "      <td>56.644113</td>\n",
       "      <td>12.954</td>\n",
       "      <td>12.713000</td>\n",
       "      <td>0.018957</td>\n",
       "      <td>9221750.0</td>\n",
       "      <td>-0.036799</td>\n",
       "      <td>0.015613</td>\n",
       "      <td>0.295485</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-10-27</td>\n",
       "      <td>AOS</td>\n",
       "      <td>51.900002</td>\n",
       "      <td>1332100.0</td>\n",
       "      <td>-0.000962</td>\n",
       "      <td>0.014431</td>\n",
       "      <td>52.561661</td>\n",
       "      <td>51.376</td>\n",
       "      <td>50.882000</td>\n",
       "      <td>0.009709</td>\n",
       "      <td>1311860.0</td>\n",
       "      <td>0.015428</td>\n",
       "      <td>0.021654</td>\n",
       "      <td>1.601343</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date Ticker       Close     Volume    Return  Volatility        RSI  \\\n",
       "0 2022-07-28    KIM   21.860001  4028800.0  0.016744    0.013179  62.512911   \n",
       "1 2022-08-01    SPG  108.629997  1650100.0 -0.000092    0.017185  65.657759   \n",
       "2 2022-08-04    FRT  105.040001   797300.0  0.008352    0.009903  59.129102   \n",
       "3 2022-08-17   AMCR   13.010000  8882400.0 -0.021068    0.017779  56.644113   \n",
       "4 2022-10-27    AOS   51.900002  1332100.0 -0.000962    0.014431  52.561661   \n",
       "\n",
       "       MA5        MA10  MA_ratio  Volume_Avg20  Volume_Spike  Momentum3  \\\n",
       "0   21.498   21.180000  0.015014     3674420.0      0.096445   0.016272   \n",
       "1  106.286  104.909999  0.013116     1648115.0      0.001204   0.043315   \n",
       "2  104.944  103.873000  0.010311      644255.0      0.237553  -0.007090   \n",
       "3   12.954   12.713000  0.018957     9221750.0     -0.036799   0.015613   \n",
       "4   51.376   50.882000  0.009709     1311860.0      0.015428   0.021654   \n",
       "\n",
       "      ATR14  DayOfWeek  Month  Target  \n",
       "0  0.522246          3      7       1  \n",
       "1  2.614542          0      8       0  \n",
       "2  2.419999          3      8       1  \n",
       "3  0.295485          2      8       0  \n",
       "4  1.601343          3     10       1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved to multi_ticker_earnings_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "# 1) Ensure the feature and label DataFrames share the same MultiIndex\n",
    "#    (Date,Ticker) before joining:\n",
    "\n",
    "# features_df should already be indexed by (Date,Ticker)\n",
    "# if not, do it explicitly:\n",
    "features_df = features_df.reset_index().set_index(['Date','Ticker'])\n",
    "\n",
    "# labels_df just needs to have the same index\n",
    "labels_df = labels_df.set_index(['Date','Ticker'])\n",
    "\n",
    "# 2) Join on that MultiIndex, pulling in only the 'Target' column from labels_df\n",
    "final_df = features_df.join(\n",
    "    labels_df[['Target']],\n",
    "    how='inner'\n",
    ").reset_index()\n",
    "\n",
    "# 3) Inspect & save\n",
    "print(\"Final dataset shape:\", final_df.shape)\n",
    "display(final_df.head())\n",
    "\n",
    "final_df.to_csv(\"multi_ticker_earnings_dataset.csv\", index=False)\n",
    "print(\"✅ Saved to multi_ticker_earnings_dataset.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
