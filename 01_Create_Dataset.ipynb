{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0171e930",
   "metadata": {},
   "source": [
    "# Multi-Ticker Earnings Dataset ‚Äî Construction Notebook\n",
    "\n",
    "This notebook programmatically builds a **multi-year, multi-ticker dataset** covering S&P 500 companies from 2004 to 2025.\n",
    "It consolidates historical market data, engineered technical indicators, and earnings-surprise information into a single feature table suitable for supervised learning.\n",
    "\n",
    "**Workflow overview:**\n",
    "\n",
    "1. Fetch the S&P 500 ticker universe from Wikipedia.\n",
    "2. Download historical OHLCV data from Yahoo Finance.\n",
    "3. Collect and merge earnings events (with Surprise %).\n",
    "4. Engineer predictive features such as RSI, ATR, momentum, and MA ratios.\n",
    "5. Generate forward-looking labels for model training.\n",
    "6. Export the finalized dataset as `multi_ticker_earnings_dataset.csv`.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4efd24",
   "metadata": {},
   "source": [
    "## Imports and Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a7b1f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ta.momentum import RSIIndicator\n",
    "from ta.volatility import AverageTrueRange\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import requests\n",
    "from tqdm.notebook import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ CONFIG ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "start_date = \"2004-01-01\"\n",
    "end_date   = \"2025-12-31\"\n",
    "horizon    = 1    # days ahead for the target\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e378b84",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Fetching S&P 500 Ticker List\n",
    "\n",
    "We begin by scraping the current S&P 500 constituents directly from Wikipedia using `requests` and `BeautifulSoup`.\n",
    "This avoids stale or incomplete local copies and ensures reproducibility of the ticker universe.\n",
    "\n",
    "**Notes:**\n",
    "\n",
    "* Headers are spoofed to bypass 403 HTTP restrictions.\n",
    "* Symbols are normalized (e.g. BRK.B ‚Üí BRK-B).\n",
    "* The function returns a list of ~500 tickers for downstream looping.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d83d1541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Fetched 503 tickers, e.g.: ['MMM', 'AOS', 'ABT', 'ABBV', 'ACN', 'ADBE', 'AMD', 'AES', 'AFL', 'A']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_47640\\262162819.py:28: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_html(str(table))[0]\n"
     ]
    }
   ],
   "source": [
    "def get_sp500_tickers():\n",
    "    \"\"\"\n",
    "    Scrape the current list of S&P 500 tickers from Wikipedia.\n",
    "    Uses requests + BeautifulSoup to avoid HTTP 403 errors.\n",
    "    \"\"\"\n",
    "    url = \"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\"\n",
    "\n",
    "    # Add browser headers to bypass bot protection\n",
    "    headers = {\n",
    "        \"User-Agent\": (\n",
    "            \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "            \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "            \"Chrome/120.0 Safari/537.36\"\n",
    "        )\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, headers=headers)\n",
    "    response.raise_for_status()   # will show any real connection error\n",
    "\n",
    "    # Parse the HTML with BeautifulSoup\n",
    "    soup = BeautifulSoup(response.text, \"lxml\")\n",
    "    table = soup.find(\"table\", {\"id\": \"constituents\"})\n",
    "\n",
    "    if table is None:\n",
    "        raise ValueError(\"Could not find the constituents table on the Wikipedia page.\")\n",
    "\n",
    "    # Extract the table using pandas\n",
    "    df = pd.read_html(str(table))[0]\n",
    "\n",
    "    tickers = [t.replace(\".\", \"-\") for t in df[\"Symbol\"].astype(str).tolist()]\n",
    "    return tickers\n",
    "\n",
    "# Usage\n",
    "sp500_tickers = get_sp500_tickers()\n",
    "print(f\"‚úÖ Fetched {len(sp500_tickers)} tickers, e.g.: {sp500_tickers[:10]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce835b4",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Initialize Ticker Universe\n",
    "\n",
    "We call `get_sp500_tickers()` to populate the `tickers` list.\n",
    "This provides the master universe for subsequent price and earnings retrieval.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90f2aa01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_47640\\262162819.py:28: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_html(str(table))[0]\n"
     ]
    }
   ],
   "source": [
    "tickers = get_sp500_tickers()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0874b913",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Download Historical Price Data\n",
    "\n",
    "We use `yfinance.download()` to pull OHLCV data for all S&P 500 tickers spanning **2004 ‚Äì 2025**.\n",
    "To avoid throttling, tickers are split into batches of 50 and fetched concurrently.\n",
    "\n",
    "**Post-processing:**\n",
    "\n",
    "* Concatenate batches horizontally into a single DataFrame.\n",
    "* Drop holiday rows where all tickers are NaN.\n",
    "\n",
    "This step produces a multi-indexed DataFrame of prices ready for feature engineering.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "385c1125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching S&P 500 ticker list‚Ä¶\n",
      "Got 503 tickers. Date range: 2004-01-01 ‚Üí 2025-12-31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_47640\\262162819.py:28: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_html(str(table))[0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e84b675c489c4187af2265120f1d3489",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üì• Downloading price data (batched):   0%|                                   | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  50 of 50 completed\n",
      "[*********************100%***********************]  50 of 50 completed\n",
      "[*********************100%***********************]  50 of 50 completed\n",
      "[*********************100%***********************]  50 of 50 completed\n",
      "[*********************100%***********************]  50 of 50 completed\n",
      "[*********************100%***********************]  50 of 50 completed\n",
      "[*********************100%***********************]  50 of 50 completed\n",
      "[*********************100%***********************]  50 of 50 completed\n",
      "[*********************100%***********************]  50 of 50 completed\n",
      "[*********************100%***********************]  50 of 50 completed\n",
      "[*********************100%***********************]  3 of 3 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Price download complete. Raw shape: (5503, 3018)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th colspan=\"6\" halign=\"left\">ABT</th>\n",
       "      <th colspan=\"4\" halign=\"left\">MO</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"4\" halign=\"left\">ZBRA</th>\n",
       "      <th colspan=\"6\" halign=\"left\">ZTS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Price</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>...</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2004-01-02</th>\n",
       "      <td>20.918781</td>\n",
       "      <td>21.165676</td>\n",
       "      <td>20.802067</td>\n",
       "      <td>20.986116</td>\n",
       "      <td>11.766494</td>\n",
       "      <td>6894172</td>\n",
       "      <td>54.669998</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>54.529999</td>\n",
       "      <td>54.650002</td>\n",
       "      <td>...</td>\n",
       "      <td>43.406666</td>\n",
       "      <td>43.586666</td>\n",
       "      <td>43.586666</td>\n",
       "      <td>339900</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-05</th>\n",
       "      <td>21.143230</td>\n",
       "      <td>21.210567</td>\n",
       "      <td>20.739222</td>\n",
       "      <td>20.986116</td>\n",
       "      <td>11.766494</td>\n",
       "      <td>14395828</td>\n",
       "      <td>54.570000</td>\n",
       "      <td>54.619999</td>\n",
       "      <td>53.590000</td>\n",
       "      <td>54.240002</td>\n",
       "      <td>...</td>\n",
       "      <td>43.393333</td>\n",
       "      <td>43.666668</td>\n",
       "      <td>43.666668</td>\n",
       "      <td>640950</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-06</th>\n",
       "      <td>20.851446</td>\n",
       "      <td>20.959183</td>\n",
       "      <td>20.721266</td>\n",
       "      <td>20.833490</td>\n",
       "      <td>11.680915</td>\n",
       "      <td>7790584</td>\n",
       "      <td>54.240002</td>\n",
       "      <td>54.299999</td>\n",
       "      <td>53.599998</td>\n",
       "      <td>53.830002</td>\n",
       "      <td>...</td>\n",
       "      <td>43.366669</td>\n",
       "      <td>43.766666</td>\n",
       "      <td>43.766666</td>\n",
       "      <td>311700</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-07</th>\n",
       "      <td>20.851446</td>\n",
       "      <td>21.053452</td>\n",
       "      <td>20.716776</td>\n",
       "      <td>21.053452</td>\n",
       "      <td>11.804256</td>\n",
       "      <td>7774322</td>\n",
       "      <td>53.759998</td>\n",
       "      <td>53.759998</td>\n",
       "      <td>52.509998</td>\n",
       "      <td>53.119999</td>\n",
       "      <td>...</td>\n",
       "      <td>43.500000</td>\n",
       "      <td>44.500000</td>\n",
       "      <td>44.500000</td>\n",
       "      <td>495150</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-08</th>\n",
       "      <td>20.424990</td>\n",
       "      <td>20.447435</td>\n",
       "      <td>20.249920</td>\n",
       "      <td>20.433968</td>\n",
       "      <td>11.456921</td>\n",
       "      <td>17053876</td>\n",
       "      <td>53.029999</td>\n",
       "      <td>53.279999</td>\n",
       "      <td>52.599998</td>\n",
       "      <td>53.099998</td>\n",
       "      <td>...</td>\n",
       "      <td>44.133331</td>\n",
       "      <td>44.599998</td>\n",
       "      <td>44.599998</td>\n",
       "      <td>290850</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 3018 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Ticker            ABT                                                        \\\n",
       "Price            Open       High        Low      Close  Adj Close    Volume   \n",
       "Date                                                                          \n",
       "2004-01-02  20.918781  21.165676  20.802067  20.986116  11.766494   6894172   \n",
       "2004-01-05  21.143230  21.210567  20.739222  20.986116  11.766494  14395828   \n",
       "2004-01-06  20.851446  20.959183  20.721266  20.833490  11.680915   7790584   \n",
       "2004-01-07  20.851446  21.053452  20.716776  21.053452  11.804256   7774322   \n",
       "2004-01-08  20.424990  20.447435  20.249920  20.433968  11.456921  17053876   \n",
       "\n",
       "Ticker             MO                                   ...       ZBRA  \\\n",
       "Price            Open       High        Low      Close  ...        Low   \n",
       "Date                                                    ...              \n",
       "2004-01-02  54.669998  55.000000  54.529999  54.650002  ...  43.406666   \n",
       "2004-01-05  54.570000  54.619999  53.590000  54.240002  ...  43.393333   \n",
       "2004-01-06  54.240002  54.299999  53.599998  53.830002  ...  43.366669   \n",
       "2004-01-07  53.759998  53.759998  52.509998  53.119999  ...  43.500000   \n",
       "2004-01-08  53.029999  53.279999  52.599998  53.099998  ...  44.133331   \n",
       "\n",
       "Ticker                                    ZTS                                  \n",
       "Price           Close  Adj Close  Volume Open High Low Close Adj Close Volume  \n",
       "Date                                                                           \n",
       "2004-01-02  43.586666  43.586666  339900  NaN  NaN NaN   NaN       NaN    NaN  \n",
       "2004-01-05  43.666668  43.666668  640950  NaN  NaN NaN   NaN       NaN    NaN  \n",
       "2004-01-06  43.766666  43.766666  311700  NaN  NaN NaN   NaN       NaN    NaN  \n",
       "2004-01-07  44.500000  44.500000  495150  NaN  NaN NaN   NaN       NaN    NaN  \n",
       "2004-01-08  44.599998  44.599998  290850  NaN  NaN NaN   NaN       NaN    NaN  \n",
       "\n",
       "[5 rows x 3018 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ‚îÄ‚îÄ Step 1: Fetch price data for the entire S&P 500 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "print(\"Fetching S&P 500 ticker list‚Ä¶\")\n",
    "tickers = get_sp500_tickers()\n",
    "print(f\"Got {len(tickers)} tickers. Date range: {start_date} ‚Üí {end_date}\")\n",
    "\n",
    "batch_size = 50\n",
    "chunks = [tickers[i:i + batch_size] for i in range(0, len(tickers), batch_size)]\n",
    "\n",
    "frames = []\n",
    "for chunk in tqdm(chunks, desc=\"üì• Downloading Price Data (batched)\", ncols=100):\n",
    "    try:\n",
    "        df_chunk = yf.download(\n",
    "            chunk,\n",
    "            start=start_date,\n",
    "            end=end_date,\n",
    "            group_by=\"ticker\",\n",
    "            auto_adjust=False,\n",
    "            threads=True\n",
    "        )\n",
    "        frames.append(df_chunk)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Batch failed ({chunk[0]} - {chunk[-1]}): {e}\")\n",
    "        continue\n",
    "\n",
    "raw = pd.concat(frames, axis=1)\n",
    "raw.dropna(how=\"all\", inplace=True)\n",
    "\n",
    "print(\"‚úÖ Price download complete. Raw shape:\", raw.shape)\n",
    "display(raw.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157a4036",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Collect Earnings Event Dates\n",
    "\n",
    "Each ticker‚Äôs earnings calendar is queried using `yf.Ticker(t).earnings_dates`.\n",
    "We aggregate all available earnings dates within the specified range and normalize timezones.\n",
    "\n",
    "**Error handling & validation:**\n",
    "\n",
    "* Tickers with no data are tracked in `bad_tickers`.\n",
    "* Valid events are merged into a master `earnings_dates` table.\n",
    "\n",
    "The output contains timestamped earnings announcements per ticker ‚Äî the foundation for label creation.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69c011f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting earnings dates for 503 tickers...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e587b1900674f4da0b975e3381f9266",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üìä Fetching earnings calendars:   0%|                                       | 0/503 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rahul\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\yfinance\\base.py:761: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['Earnings Date'] = pd.to_datetime(df['Event Start Date'])\n",
      "FOX: $FOX: possibly delisted; no earnings dates found\n",
      "NWS: $NWS: possibly delisted; no earnings dates found\n",
      "PSKY: $PSKY: possibly delisted; no earnings dates found\n",
      "Q: $Q: possibly delisted; no earnings dates found\n",
      "SOLS: $SOLS: possibly delisted; no earnings dates found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Total valid earnings events: 5893\n",
      "üö´ Skipped 5 tickers (no data)\n"
     ]
    }
   ],
   "source": [
    "bad_tickers = []\n",
    "events = []\n",
    "\n",
    "print(f\"Collecting earnings dates for {len(tickers)} tickers...\")\n",
    "\n",
    "for t in tqdm(tickers, desc=\"üìä Fetching earnings calendars\", ncols=100):\n",
    "    try:\n",
    "        ticker_obj = yf.Ticker(t)\n",
    "        ed = ticker_obj.earnings_dates\n",
    "\n",
    "        if ed is None or ed.empty:\n",
    "            bad_tickers.append(t)\n",
    "            continue\n",
    "\n",
    "        ed = ed.reset_index()\n",
    "        ed.columns = [\"Date\", \"Estimate\", \"Reported\", \"Surprise_%\"]\n",
    "        ed[\"Date\"] = ed[\"Date\"].dt.tz_localize(None).dt.normalize()\n",
    "        ed[\"Ticker\"] = t\n",
    "        events.append(ed[[\"Date\", \"Ticker\"]])\n",
    "\n",
    "    except Exception as e:\n",
    "        bad_tickers.append(t)\n",
    "        continue\n",
    "\n",
    "if events:\n",
    "    earnings_dates = (\n",
    "        pd.concat(events, ignore_index=True)\n",
    "        .query(\"@start_date <= Date <= @end_date\")\n",
    "        .sort_values([\"Date\", \"Ticker\"])\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "else:\n",
    "    earnings_dates = pd.DataFrame(columns=[\"Date\", \"Ticker\"])\n",
    "\n",
    "print(f\"‚úÖ Total valid earnings events: {len(earnings_dates)}\")\n",
    "print(f\"üö´ Skipped {len(bad_tickers)} tickers (no data)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324a78ea",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Enrich Earnings Events with Surprise %\n",
    "\n",
    "We rebuild the `earnings_dates` DataFrame to explicitly include **Earnings Surprise %**, which quantifies how reported earnings differed from analyst expectations.\n",
    "\n",
    "**Key notes:**\n",
    "\n",
    "* Only ‚Äúgood‚Äù tickers from the previous step are processed.\n",
    "* Missing Surprise % values are handled gracefully.\n",
    "* Output is sorted chronologically and indexed by `Date` and `Ticker`.\n",
    "\n",
    "This forms a clean event dataset alignable with price data for feature merging.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1dd2256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 498 valid tickers (skipping 5 bad ones)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rahul\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\yfinance\\base.py:761: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['Earnings Date'] = pd.to_datetime(df['Event Start Date'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Total earnings events (with Surprise_%): 5893\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Surprise_%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-08-05</td>\n",
       "      <td>FISV</td>\n",
       "      <td>-0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-10-27</td>\n",
       "      <td>FISV</td>\n",
       "      <td>3.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-02-09</td>\n",
       "      <td>FISV</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-04-27</td>\n",
       "      <td>FISV</td>\n",
       "      <td>3.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-07-27</td>\n",
       "      <td>FISV</td>\n",
       "      <td>7.04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date Ticker  Surprise_%\n",
       "0 2020-08-05   FISV       -0.09\n",
       "1 2020-10-27   FISV        3.62\n",
       "2 2021-02-09   FISV        0.76\n",
       "3 2021-04-27   FISV        3.71\n",
       "4 2021-07-27   FISV        7.04"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 2 ‚Äî Build unified earnings_dates with Surprise_% included\n",
    "events = []\n",
    "\n",
    "# Filter tickers to exclude those with no data (collected earlier)\n",
    "good_tickers = [t for t in tickers if t not in bad_tickers]\n",
    "print(f\"Processing {len(good_tickers)} valid tickers (skipping {len(bad_tickers)} bad ones)\")\n",
    "\n",
    "for t in good_tickers:\n",
    "    try:\n",
    "        ed = yf.Ticker(t).earnings_dates\n",
    "        if ed is None or ed.empty:\n",
    "            print(f\"‚ö†Ô∏è  No earnings data for {t} ‚Äî skipping\")\n",
    "            bad_tickers.append(t)\n",
    "            continue\n",
    "\n",
    "        ed = ed.reset_index()\n",
    "        ed.columns = [\"Date\", \"Earnings_Estimate\", \"Reported_Earnings\", \"Surprise_%\"]\n",
    "        ed[\"Date\"] = ed[\"Date\"].dt.tz_localize(None).dt.normalize()\n",
    "        ed[\"Ticker\"] = t\n",
    "        events.append(ed[[\"Date\", \"Ticker\", \"Surprise_%\"]])\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå {t}: {e}\")\n",
    "        bad_tickers.append(t)\n",
    "        continue\n",
    "\n",
    "earnings_dates = (\n",
    "    pd.concat(events, ignore_index=True)\n",
    "      .query(\"@start_date <= Date <= @end_date\")\n",
    "      .sort_values([\"Date\", \"Ticker\"])\n",
    "      .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Total earnings events (with Surprise_%): {len(earnings_dates)}\")\n",
    "display(earnings_dates.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a292de65",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Feature Engineering\n",
    "\n",
    "For each ticker:\n",
    "\n",
    "1. Extract and clean the OHLCV data.\n",
    "2. Compute technical indicators:\n",
    "   ‚ÄÉ- **Return**, **Volatility**, **RSI**, **Moving Averages (5 & 10 days)**, **MA Ratio**\n",
    "   ‚ÄÉ- **Volume metrics** (20-day average and spike ratio)\n",
    "   ‚ÄÉ- **Momentum (3-day change)** and **ATR14** for true range volatility\n",
    "   ‚ÄÉ- **Temporal features** (weekday, month)\n",
    "3. Merge earnings **Surprise %** to capture event context and set non-event days to zero.\n",
    "\n",
    "After rolling-window cleanup, all features are concatenated across tickers into `features_df`.\n",
    "\n",
    "**Outcome:**\n",
    "A comprehensive multi-ticker DataFrame spanning price, momentum, volatility, volume, and event-driven signals.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a671c758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineering features for 498 tickers...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42bdf0ba0b424a4d810815c702a42af3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "‚öôÔ∏è Feature engineering:   0%|                                               | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå No ticker produced valid feature data. Check 'skipped' list below.\n",
      "\n",
      "‚ö†Ô∏è  Skipped 498 tickers (sample):\n",
      "[('MMM', 'error:\"[\\'Surprise_%\\'] not in index\"'), ('AOS', 'error:\"[\\'Surprise_%\\'] not in index\"'), ('ABT', 'error:\"[\\'Surprise_%\\'] not in index\"'), ('ABBV', 'error:\"[\\'Surprise_%\\'] not in index\"'), ('ACN', 'error:\"[\\'Surprise_%\\'] not in index\"'), ('ADBE', 'error:\"[\\'Surprise_%\\'] not in index\"'), ('AMD', 'error:\"[\\'Surprise_%\\'] not in index\"'), ('AES', 'error:\"[\\'Surprise_%\\'] not in index\"'), ('AFL', 'error:\"[\\'Surprise_%\\'] not in index\"'), ('A', 'error:\"[\\'Surprise_%\\'] not in index\"')]\n"
     ]
    }
   ],
   "source": [
    "feature_list = []\n",
    "skipped = []\n",
    "\n",
    "good_tickers = [t for t in tickers if t not in bad_tickers]\n",
    "\n",
    "print(f\"Engineering features for {len(good_tickers)} tickers...\")\n",
    "\n",
    "for t in tqdm(good_tickers, desc=\"‚öôÔ∏è Feature engineering\", ncols=100):\n",
    "    try:\n",
    "        # Check if ticker exists in raw data\n",
    "        if t not in raw.columns.get_level_values(0):\n",
    "            skipped.append((t, \"missing_in_raw\"))\n",
    "            continue\n",
    "\n",
    "        df_t = raw[t].copy()\n",
    "\n",
    "        # Flatten possible MultiIndex columns\n",
    "        if isinstance(df_t.columns, pd.MultiIndex):\n",
    "            df_t.columns = df_t.columns.get_level_values(0)\n",
    "\n",
    "        # Clean and ensure numeric\n",
    "        df_t.drop(columns=[c for c in [\"Price\"] if c in df_t], inplace=True, errors=\"ignore\")\n",
    "        df_t[\"Close\"]  = pd.to_numeric(df_t[\"Close\"],  errors=\"coerce\")\n",
    "        df_t[\"Volume\"] = pd.to_numeric(df_t[\"Volume\"], errors=\"coerce\")\n",
    "        df_t.dropna(subset=[\"Close\", \"Volume\"], inplace=True)\n",
    "        if df_t.empty:\n",
    "            skipped.append((t, \"empty_after_clean\"))\n",
    "            continue\n",
    "\n",
    "        # Core features\n",
    "        df_t[\"Return\"]      = df_t[\"Close\"].pct_change()\n",
    "        df_t[\"Volatility\"]  = df_t[\"Return\"].rolling(5).std()\n",
    "        df_t[\"RSI\"]         = RSIIndicator(close=df_t[\"Close\"], window=14).rsi()\n",
    "        df_t[\"MA5\"]         = df_t[\"Close\"].rolling(5).mean()\n",
    "        df_t[\"MA10\"]        = df_t[\"Close\"].rolling(10).mean()\n",
    "        df_t[\"MA_ratio\"]    = df_t[\"MA5\"] / df_t[\"MA10\"] - 1\n",
    "        df_t[\"Volume_Avg20\"]= df_t[\"Volume\"].rolling(20).mean()\n",
    "        df_t[\"Volume_Spike\"]= df_t[\"Volume\"] / df_t[\"Volume_Avg20\"] - 1\n",
    "        df_t[\"Momentum3\"]   = df_t[\"Close\"].pct_change(3)\n",
    "        atr = AverageTrueRange(high=df_t[\"High\"], low=df_t[\"Low\"],\n",
    "                               close=df_t[\"Close\"], window=14)\n",
    "        df_t[\"ATR14\"] = atr.average_true_range()\n",
    "        df_t[\"DayOfWeek\"] = df_t.index.dayofweek\n",
    "        df_t[\"Month\"]     = df_t.index.month\n",
    "\n",
    "        # Merge Surprise_% (can be missing for some tickers)\n",
    "        ed_t = earnings_dates.loc[earnings_dates[\"Ticker\"] == t, [\"Date\", \"Surprise_%\"]].set_index(\"Date\")\n",
    "        df_t = df_t.join(ed_t, how=\"left\")\n",
    "        df_t[\"Surprise_%\"] = df_t[\"Surprise_%\"].fillna(0)\n",
    "\n",
    "        # Drop NaNs created by rolling windows\n",
    "        df_t.dropna(subset=[\n",
    "            \"Return\",\"Volatility\",\"RSI\",\"MA5\",\"MA10\",\"MA_ratio\",\n",
    "            \"Volume_Avg20\",\"Volume_Spike\",\"Momentum3\",\"ATR14\"\n",
    "        ], inplace=True)\n",
    "\n",
    "        if df_t.empty:\n",
    "            skipped.append((t, \"empty_after_features\"))\n",
    "            continue\n",
    "\n",
    "        # Final selection\n",
    "        keep = [\n",
    "            \"Close\",\"Volume\",\"Return\",\"Volatility\",\"RSI\",\"MA5\",\"MA10\",\"MA_ratio\",\n",
    "            \"Volume_Avg20\",\"Volume_Spike\",\"Momentum3\",\"ATR14\",\n",
    "            \"DayOfWeek\",\"Month\",\"Surprise_%\"\n",
    "        ]\n",
    "        feats = df_t[keep].copy()\n",
    "        feats[\"Ticker\"] = t\n",
    "\n",
    "        feature_list.append(feats)\n",
    "\n",
    "    except Exception as e:\n",
    "        skipped.append((t, f\"error:{str(e)[:50]}\"))\n",
    "        continue\n",
    "\n",
    "# Combine all successful DataFrames\n",
    "if feature_list:\n",
    "    features_df = pd.concat(feature_list)\n",
    "    features_df.index.name = \"Date\"\n",
    "    features_df = features_df.sort_index()\n",
    "    print(f\"‚úÖ Feature engineering complete: {len(feature_list)} tickers succeeded.\")\n",
    "    print(f\"üìä Combined dataset shape: {features_df.shape}\")\n",
    "    display(features_df.head())\n",
    "else:\n",
    "    print(\"‚ùå No ticker produced valid feature data. Check 'skipped' list below.\")\n",
    "    features_df = pd.DataFrame()\n",
    "\n",
    "# Optional: view a few skip reasons\n",
    "if skipped:\n",
    "    print(f\"\\n‚ö†Ô∏è  Skipped {len(skipped)} tickers (sample):\")\n",
    "    print(skipped[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10473331",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ Target Label Generation\n",
    "\n",
    "We define a labeling function that assigns a binary target ( `Target = 1` if the price rises within the next *horizon* days, else 0 ).\n",
    "\n",
    "**Mechanism:**\n",
    "\n",
    "* Shift the closing price forward by the chosen horizon ( e.g. 1‚Äì3 days ).\n",
    "* Compare future returns at each earnings date to classify directional movement.\n",
    "\n",
    "This creates a balanced event-based label dataset linking post-earnings performance to the feature window.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c1d5548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labeled 5876 events:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-08-05</td>\n",
       "      <td>FISV</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-10-27</td>\n",
       "      <td>FISV</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-02-09</td>\n",
       "      <td>FISV</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-04-27</td>\n",
       "      <td>FISV</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-07-27</td>\n",
       "      <td>FISV</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5871</th>\n",
       "      <td>2025-06-25</td>\n",
       "      <td>GIS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5872</th>\n",
       "      <td>2025-06-25</td>\n",
       "      <td>MU</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5873</th>\n",
       "      <td>2025-06-25</td>\n",
       "      <td>PAYX</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5874</th>\n",
       "      <td>2025-06-26</td>\n",
       "      <td>MKC</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5875</th>\n",
       "      <td>2025-06-26</td>\n",
       "      <td>NKE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5876 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date Ticker  Target\n",
       "0    2020-08-05   FISV       1\n",
       "1    2020-10-27   FISV       0\n",
       "2    2021-02-09   FISV       0\n",
       "3    2021-04-27   FISV       1\n",
       "4    2021-07-27   FISV       0\n",
       "...         ...    ...     ...\n",
       "5871 2025-06-25    GIS       0\n",
       "5872 2025-06-25     MU       0\n",
       "5873 2025-06-25   PAYX       1\n",
       "5874 2025-06-26    MKC       0\n",
       "5875 2025-06-26    NKE       1\n",
       "\n",
       "[5876 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 4: Label creation (target variable) for multi‚Äêticker MultiIndex\n",
    "\n",
    "def create_labels(event_dates, price_df, horizon=3):\n",
    "    \"\"\"\n",
    "    event_dates: DataFrame with ['Date','Ticker'] columns of pd.Timestamps\n",
    "    price_df:    DataFrame with a MultiIndex (Date, Ticker) and at least a 'Close' column\n",
    "    horizon:     how many trading days ahead to look\n",
    "    \"\"\"\n",
    "    labels = []\n",
    "    # 1) pre‚Äêshift the Close series within each ticker\n",
    "    future_close = price_df['Close'].groupby(level='Ticker').shift(-horizon)\n",
    "    \n",
    "    for _, ev in event_dates.iterrows():\n",
    "        dt, tkr = ev['Date'], ev['Ticker']\n",
    "        key = (dt, tkr)\n",
    "        # 2) skip if that (Date, Ticker) combo isn't in your features\n",
    "        if key not in price_df.index:\n",
    "            continue\n",
    "        \n",
    "        past = price_df.at[key, 'Close']\n",
    "        fut  = future_close.at[key]\n",
    "        # 3) skip if we ran off the end\n",
    "        if pd.isna(fut):\n",
    "            continue\n",
    "        \n",
    "        ret = (fut - past) / past\n",
    "        labels.append({\n",
    "          'Date':   dt,\n",
    "          'Ticker': tkr,\n",
    "          'Target': int(ret > 0)\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(labels)\n",
    "\n",
    "\n",
    "# ‚Äî how to call it ‚Äî\n",
    "# make sure features_df is a MultiIndexed DF: index names must be ['Date','Ticker']\n",
    "features_df = features_df.reset_index().set_index(['Date','Ticker'])\n",
    "\n",
    "labels_df = create_labels(earnings_dates, features_df, horizon=horizon)\n",
    "print(f\"Labeled {len(labels_df)} events:\")\n",
    "display(labels_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b05144",
   "metadata": {},
   "source": [
    "## 8Ô∏è‚É£ Assemble Final Dataset and Export\n",
    "\n",
    "Finally, we join `features_df` and `labels_df` on their shared MultiIndex (`Date`, `Ticker`).\n",
    "Only entries with valid targets are retained for supervised learning.\n",
    "\n",
    "**Output:**\n",
    "\n",
    "* A fully aligned feature-label table ready for model training.\n",
    "* Saved as `multi_ticker_earnings_dataset.csv`.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84a4caf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final dataset shape: (5876, 18)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Return</th>\n",
       "      <th>Volatility</th>\n",
       "      <th>RSI</th>\n",
       "      <th>MA5</th>\n",
       "      <th>MA10</th>\n",
       "      <th>MA_ratio</th>\n",
       "      <th>Volume_Avg20</th>\n",
       "      <th>Volume_Spike</th>\n",
       "      <th>Momentum3</th>\n",
       "      <th>ATR14</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Month</th>\n",
       "      <th>Surprise_%</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-08-05</td>\n",
       "      <td>FISV</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>5283200.0</td>\n",
       "      <td>-0.016558</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>43.912461</td>\n",
       "      <td>99.686000</td>\n",
       "      <td>100.367001</td>\n",
       "      <td>-0.006785</td>\n",
       "      <td>4060355.0</td>\n",
       "      <td>0.301167</td>\n",
       "      <td>-0.017938</td>\n",
       "      <td>2.584196</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-10-27</td>\n",
       "      <td>FISV</td>\n",
       "      <td>96.610001</td>\n",
       "      <td>6889300.0</td>\n",
       "      <td>-0.017991</td>\n",
       "      <td>0.017073</td>\n",
       "      <td>38.957956</td>\n",
       "      <td>99.281999</td>\n",
       "      <td>100.041999</td>\n",
       "      <td>-0.007597</td>\n",
       "      <td>3848190.0</td>\n",
       "      <td>0.790270</td>\n",
       "      <td>-0.042327</td>\n",
       "      <td>2.814527</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>3.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-02-09</td>\n",
       "      <td>FISV</td>\n",
       "      <td>113.449997</td>\n",
       "      <td>3774700.0</td>\n",
       "      <td>0.000441</td>\n",
       "      <td>0.008138</td>\n",
       "      <td>59.238398</td>\n",
       "      <td>112.301999</td>\n",
       "      <td>108.918999</td>\n",
       "      <td>0.031060</td>\n",
       "      <td>5266415.0</td>\n",
       "      <td>-0.283251</td>\n",
       "      <td>0.010780</td>\n",
       "      <td>2.884962</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-04-27</td>\n",
       "      <td>FISV</td>\n",
       "      <td>121.660004</td>\n",
       "      <td>9036900.0</td>\n",
       "      <td>-0.038641</td>\n",
       "      <td>0.019613</td>\n",
       "      <td>44.317565</td>\n",
       "      <td>124.736000</td>\n",
       "      <td>124.783999</td>\n",
       "      <td>-0.000385</td>\n",
       "      <td>3871125.0</td>\n",
       "      <td>1.334438</td>\n",
       "      <td>-0.023830</td>\n",
       "      <td>2.235447</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3.71</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-07-27</td>\n",
       "      <td>FISV</td>\n",
       "      <td>114.680000</td>\n",
       "      <td>8285000.0</td>\n",
       "      <td>0.029906</td>\n",
       "      <td>0.013433</td>\n",
       "      <td>63.271989</td>\n",
       "      <td>111.582001</td>\n",
       "      <td>110.515000</td>\n",
       "      <td>0.009655</td>\n",
       "      <td>3838160.0</td>\n",
       "      <td>1.158586</td>\n",
       "      <td>0.042072</td>\n",
       "      <td>2.141160</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>7.04</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date Ticker       Close     Volume    Return  Volatility        RSI  \\\n",
       "0 2020-08-05   FISV   98.000000  5283200.0 -0.016558    0.008797  43.912461   \n",
       "1 2020-10-27   FISV   96.610001  6889300.0 -0.017991    0.017073  38.957956   \n",
       "2 2021-02-09   FISV  113.449997  3774700.0  0.000441    0.008138  59.238398   \n",
       "3 2021-04-27   FISV  121.660004  9036900.0 -0.038641    0.019613  44.317565   \n",
       "4 2021-07-27   FISV  114.680000  8285000.0  0.029906    0.013433  63.271989   \n",
       "\n",
       "          MA5        MA10  MA_ratio  Volume_Avg20  Volume_Spike  Momentum3  \\\n",
       "0   99.686000  100.367001 -0.006785     4060355.0      0.301167  -0.017938   \n",
       "1   99.281999  100.041999 -0.007597     3848190.0      0.790270  -0.042327   \n",
       "2  112.301999  108.918999  0.031060     5266415.0     -0.283251   0.010780   \n",
       "3  124.736000  124.783999 -0.000385     3871125.0      1.334438  -0.023830   \n",
       "4  111.582001  110.515000  0.009655     3838160.0      1.158586   0.042072   \n",
       "\n",
       "      ATR14  DayOfWeek  Month  Surprise_%  Target  \n",
       "0  2.584196          2      8       -0.09       1  \n",
       "1  2.814527          1     10        3.62       0  \n",
       "2  2.884962          1      2        0.76       0  \n",
       "3  2.235447          1      4        3.71       1  \n",
       "4  2.141160          1      7        7.04       0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved to multi_ticker_earnings_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "# 1) Ensure the feature and label DataFrames share the same MultiIndex\n",
    "#    (Date,Ticker) before joining:\n",
    "\n",
    "# features_df should already be indexed by (Date,Ticker)\n",
    "# if not, do it explicitly:\n",
    "features_df = features_df.reset_index().set_index(['Date','Ticker'])\n",
    "\n",
    "# labels_df just needs to have the same index\n",
    "labels_df = labels_df.set_index(['Date','Ticker'])\n",
    "\n",
    "# 2) Join on that MultiIndex, pulling in only the 'Target' column from labels_df\n",
    "final_df = features_df.join(\n",
    "    labels_df[['Target']],\n",
    "    how='inner'\n",
    ").reset_index()\n",
    "\n",
    "# 3) Inspect & save\n",
    "print(\"Final dataset shape:\", final_df.shape)\n",
    "display(final_df.head())\n",
    "\n",
    "final_df.to_csv(\"multi_ticker_earnings_dataset.csv\", index=False)\n",
    "print(\"‚úÖ Saved to multi_ticker_earnings_dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4541dec3",
   "metadata": {},
   "source": [
    "## ‚úÖ Summary\n",
    "\n",
    "This dataset-creation pipeline automates the integration of market and fundamental signals for hundreds of equities over two decades.\n",
    "\n",
    "**Key benefits:**\n",
    "\n",
    "* Unified multi-ticker structure for cross-sectional analysis.\n",
    "* Rich feature space combining momentum, risk, and surprise factors.\n",
    "* Forward-looking labels supporting classification or forecasting tasks.\n",
    "\n",
    "The resulting dataset serves as a robust foundation for volatility modeling, event prediction, and machine-learning experiments in financial time series research.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
