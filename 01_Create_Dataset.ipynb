{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0171e930",
   "metadata": {},
   "source": [
    "# Generating dataset for ML classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4efd24",
   "metadata": {},
   "source": [
    "## Imports and Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a7b1f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ta.momentum import RSIIndicator\n",
    "from ta.volatility import AverageTrueRange\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# ─── CONFIG ────────────────────────────────────\n",
    "start_date = \"2004-01-01\"\n",
    "end_date   = \"2025-12-31\"\n",
    "horizon    = 1    # days ahead for the target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d83d1541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fetched 503 tickers, e.g.: ['MMM', 'AOS', 'ABT', 'ABBV', 'ACN', 'ADBE', 'AMD', 'AES', 'AFL', 'A']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_39944\\262162819.py:28: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_html(str(table))[0]\n"
     ]
    }
   ],
   "source": [
    "def get_sp500_tickers():\n",
    "    \"\"\"\n",
    "    Scrape the current list of S&P 500 tickers from Wikipedia.\n",
    "    Uses requests + BeautifulSoup to avoid HTTP 403 errors.\n",
    "    \"\"\"\n",
    "    url = \"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\"\n",
    "\n",
    "    # Add browser headers to bypass bot protection\n",
    "    headers = {\n",
    "        \"User-Agent\": (\n",
    "            \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "            \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "            \"Chrome/120.0 Safari/537.36\"\n",
    "        )\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, headers=headers)\n",
    "    response.raise_for_status()   # will show any real connection error\n",
    "\n",
    "    # Parse the HTML with BeautifulSoup\n",
    "    soup = BeautifulSoup(response.text, \"lxml\")\n",
    "    table = soup.find(\"table\", {\"id\": \"constituents\"})\n",
    "\n",
    "    if table is None:\n",
    "        raise ValueError(\"Could not find the constituents table on the Wikipedia page.\")\n",
    "\n",
    "    # Extract the table using pandas\n",
    "    df = pd.read_html(str(table))[0]\n",
    "\n",
    "    tickers = [t.replace(\".\", \"-\") for t in df[\"Symbol\"].astype(str).tolist()]\n",
    "    return tickers\n",
    "\n",
    "# Usage\n",
    "sp500_tickers = get_sp500_tickers()\n",
    "print(f\"✅ Fetched {len(sp500_tickers)} tickers, e.g.: {sp500_tickers[:10]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90f2aa01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_39944\\262162819.py:28: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_html(str(table))[0]\n"
     ]
    }
   ],
   "source": [
    "tickers = get_sp500_tickers()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0874b913",
   "metadata": {},
   "source": [
    "## Step 1: Fetch Price Data for All Tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "385c1125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching S&P 500 ticker list…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_39944\\262162819.py:28: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_html(str(table))[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 503 tickers. Date range: 2004-01-01 → 2025-12-31\n",
      "  Downloading tickers MMM … ADSK …\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  50 of 50 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading tickers ADP … CMG …\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  50 of 50 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading tickers CB … D …\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  50 of 50 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading tickers DPZ … FTNT …\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  50 of 50 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading tickers FTV … IBKR …\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  50 of 50 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading tickers ICE … MMC …\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  50 of 50 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading tickers MLM … OXY …\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  50 of 50 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading tickers ODFL … ROK …\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  50 of 50 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading tickers ROL … TT …\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  50 of 50 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading tickers TDG … YUM …\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  50 of 50 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading tickers ZBRA … ZTS …\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  3 of 3 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Price download complete. Raw shape: (5495, 3018)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th colspan=\"6\" halign=\"left\">GOOG</th>\n",
       "      <th colspan=\"4\" halign=\"left\">AJG</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"4\" halign=\"left\">ZBH</th>\n",
       "      <th colspan=\"6\" halign=\"left\">ZBRA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Price</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>...</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2004-01-02</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.400002</td>\n",
       "      <td>32.650002</td>\n",
       "      <td>31.740000</td>\n",
       "      <td>31.950001</td>\n",
       "      <td>...</td>\n",
       "      <td>67.864075</td>\n",
       "      <td>67.961166</td>\n",
       "      <td>60.486706</td>\n",
       "      <td>688143</td>\n",
       "      <td>44.126667</td>\n",
       "      <td>44.186668</td>\n",
       "      <td>43.406666</td>\n",
       "      <td>43.586666</td>\n",
       "      <td>43.586666</td>\n",
       "      <td>339900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-05</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.969999</td>\n",
       "      <td>32.810001</td>\n",
       "      <td>31.969999</td>\n",
       "      <td>32.310001</td>\n",
       "      <td>...</td>\n",
       "      <td>66.990288</td>\n",
       "      <td>67.349518</td>\n",
       "      <td>59.942310</td>\n",
       "      <td>1223846</td>\n",
       "      <td>43.486668</td>\n",
       "      <td>44.180000</td>\n",
       "      <td>43.393333</td>\n",
       "      <td>43.666668</td>\n",
       "      <td>43.666668</td>\n",
       "      <td>640950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-06</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.400002</td>\n",
       "      <td>32.419998</td>\n",
       "      <td>31.450001</td>\n",
       "      <td>31.620001</td>\n",
       "      <td>...</td>\n",
       "      <td>66.252426</td>\n",
       "      <td>67.019417</td>\n",
       "      <td>59.648548</td>\n",
       "      <td>1202216</td>\n",
       "      <td>43.566666</td>\n",
       "      <td>43.886665</td>\n",
       "      <td>43.366669</td>\n",
       "      <td>43.766666</td>\n",
       "      <td>43.766666</td>\n",
       "      <td>311700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-07</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.620001</td>\n",
       "      <td>31.740000</td>\n",
       "      <td>31.379999</td>\n",
       "      <td>31.709999</td>\n",
       "      <td>...</td>\n",
       "      <td>66.912621</td>\n",
       "      <td>67.766991</td>\n",
       "      <td>60.313881</td>\n",
       "      <td>866127</td>\n",
       "      <td>43.633331</td>\n",
       "      <td>44.653332</td>\n",
       "      <td>43.500000</td>\n",
       "      <td>44.500000</td>\n",
       "      <td>44.500000</td>\n",
       "      <td>495150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-08</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.799999</td>\n",
       "      <td>32.209999</td>\n",
       "      <td>31.650000</td>\n",
       "      <td>32.080002</td>\n",
       "      <td>...</td>\n",
       "      <td>67.592232</td>\n",
       "      <td>69.077667</td>\n",
       "      <td>61.480404</td>\n",
       "      <td>1114151</td>\n",
       "      <td>44.939999</td>\n",
       "      <td>45.246666</td>\n",
       "      <td>44.133331</td>\n",
       "      <td>44.599998</td>\n",
       "      <td>44.599998</td>\n",
       "      <td>290850</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3018 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Ticker     GOOG                                        AJG             \\\n",
       "Price      Open High Low Close Adj Close Volume       Open       High   \n",
       "Date                                                                    \n",
       "2004-01-02  NaN  NaN NaN   NaN       NaN    NaN  32.400002  32.650002   \n",
       "2004-01-05  NaN  NaN NaN   NaN       NaN    NaN  31.969999  32.810001   \n",
       "2004-01-06  NaN  NaN NaN   NaN       NaN    NaN  32.400002  32.419998   \n",
       "2004-01-07  NaN  NaN NaN   NaN       NaN    NaN  31.620001  31.740000   \n",
       "2004-01-08  NaN  NaN NaN   NaN       NaN    NaN  31.799999  32.209999   \n",
       "\n",
       "Ticker                            ...        ZBH                        \\\n",
       "Price             Low      Close  ...        Low      Close  Adj Close   \n",
       "Date                              ...                                    \n",
       "2004-01-02  31.740000  31.950001  ...  67.864075  67.961166  60.486706   \n",
       "2004-01-05  31.969999  32.310001  ...  66.990288  67.349518  59.942310   \n",
       "2004-01-06  31.450001  31.620001  ...  66.252426  67.019417  59.648548   \n",
       "2004-01-07  31.379999  31.709999  ...  66.912621  67.766991  60.313881   \n",
       "2004-01-08  31.650000  32.080002  ...  67.592232  69.077667  61.480404   \n",
       "\n",
       "Ticker                    ZBRA                                              \\\n",
       "Price        Volume       Open       High        Low      Close  Adj Close   \n",
       "Date                                                                         \n",
       "2004-01-02   688143  44.126667  44.186668  43.406666  43.586666  43.586666   \n",
       "2004-01-05  1223846  43.486668  44.180000  43.393333  43.666668  43.666668   \n",
       "2004-01-06  1202216  43.566666  43.886665  43.366669  43.766666  43.766666   \n",
       "2004-01-07   866127  43.633331  44.653332  43.500000  44.500000  44.500000   \n",
       "2004-01-08  1114151  44.939999  45.246666  44.133331  44.599998  44.599998   \n",
       "\n",
       "Ticker              \n",
       "Price       Volume  \n",
       "Date                \n",
       "2004-01-02  339900  \n",
       "2004-01-05  640950  \n",
       "2004-01-06  311700  \n",
       "2004-01-07  495150  \n",
       "2004-01-08  290850  \n",
       "\n",
       "[5 rows x 3018 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ── Step 1: Fetch price data for the entire S&P 500 ───────────\n",
    "print(\"Fetching S&P 500 ticker list…\")\n",
    "tickers = get_sp500_tickers()\n",
    "print(f\"Got {len(tickers)} tickers. Date range: {start_date} → {end_date}\")\n",
    "\n",
    "# batch size to avoid timeouts / throttling\n",
    "batch_size = 50\n",
    "chunks = [tickers[i:i+batch_size] for i in range(0, len(tickers), batch_size)]\n",
    "\n",
    "frames = []\n",
    "for chunk in chunks:\n",
    "    print(f\"  Downloading tickers {chunk[0]} … {chunk[-1]} …\")\n",
    "    df_chunk = yf.download(\n",
    "        chunk,\n",
    "        start=start_date,\n",
    "        end=end_date,\n",
    "        group_by=\"ticker\",\n",
    "        auto_adjust=False,\n",
    "        threads=True\n",
    "    )\n",
    "    frames.append(df_chunk)\n",
    "\n",
    "# concatenate all batches side-by-side\n",
    "raw = pd.concat(frames, axis=1)\n",
    "\n",
    "# drop rows where *all* tickers missed (e.g. holidays)\n",
    "raw.dropna(how=\"all\", inplace=True)\n",
    "\n",
    "print(\"✅ Price download complete. Raw shape:\", raw.shape)\n",
    "display(raw.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157a4036",
   "metadata": {},
   "source": [
    "## Step 2: Build Unified Event Dates Table (Earnings Only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cae9d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MMM',\n",
       " 'AOS',\n",
       " 'ABT',\n",
       " 'ABBV',\n",
       " 'ACN',\n",
       " 'ADBE',\n",
       " 'AMD',\n",
       " 'AES',\n",
       " 'AFL',\n",
       " 'A',\n",
       " 'APD',\n",
       " 'ABNB',\n",
       " 'AKAM',\n",
       " 'ALB',\n",
       " 'ARE',\n",
       " 'ALGN',\n",
       " 'ALLE',\n",
       " 'LNT',\n",
       " 'ALL',\n",
       " 'GOOGL',\n",
       " 'GOOG',\n",
       " 'MO',\n",
       " 'AMZN',\n",
       " 'AMCR',\n",
       " 'AEE',\n",
       " 'AEP',\n",
       " 'AXP',\n",
       " 'AIG',\n",
       " 'AMT',\n",
       " 'AWK',\n",
       " 'AMP',\n",
       " 'AME',\n",
       " 'AMGN',\n",
       " 'APH',\n",
       " 'ADI',\n",
       " 'AON',\n",
       " 'APA',\n",
       " 'APO',\n",
       " 'AAPL',\n",
       " 'AMAT',\n",
       " 'APP',\n",
       " 'APTV',\n",
       " 'ACGL',\n",
       " 'ADM',\n",
       " 'ANET',\n",
       " 'AJG',\n",
       " 'AIZ',\n",
       " 'T',\n",
       " 'ATO',\n",
       " 'ADSK',\n",
       " 'ADP',\n",
       " 'AZO',\n",
       " 'AVB',\n",
       " 'AVY',\n",
       " 'AXON',\n",
       " 'BKR',\n",
       " 'BALL',\n",
       " 'BAC',\n",
       " 'BAX',\n",
       " 'BDX',\n",
       " 'BRK-B',\n",
       " 'BBY',\n",
       " 'TECH',\n",
       " 'BIIB',\n",
       " 'BLK',\n",
       " 'BX',\n",
       " 'XYZ',\n",
       " 'BK',\n",
       " 'BA',\n",
       " 'BKNG',\n",
       " 'BSX',\n",
       " 'BMY',\n",
       " 'AVGO',\n",
       " 'BR',\n",
       " 'BRO',\n",
       " 'BF-B',\n",
       " 'BLDR',\n",
       " 'BG',\n",
       " 'BXP',\n",
       " 'CHRW',\n",
       " 'CDNS',\n",
       " 'CPT',\n",
       " 'CPB',\n",
       " 'COF',\n",
       " 'CAH',\n",
       " 'CCL',\n",
       " 'CARR',\n",
       " 'CAT',\n",
       " 'CBOE',\n",
       " 'CBRE',\n",
       " 'CDW',\n",
       " 'COR',\n",
       " 'CNC',\n",
       " 'CNP',\n",
       " 'CF',\n",
       " 'CRL',\n",
       " 'SCHW',\n",
       " 'CHTR',\n",
       " 'CVX',\n",
       " 'CMG',\n",
       " 'CB',\n",
       " 'CHD',\n",
       " 'CI',\n",
       " 'CINF',\n",
       " 'CTAS',\n",
       " 'CSCO',\n",
       " 'C',\n",
       " 'CFG',\n",
       " 'CLX',\n",
       " 'CME',\n",
       " 'CMS',\n",
       " 'KO',\n",
       " 'CTSH',\n",
       " 'COIN',\n",
       " 'CL',\n",
       " 'CMCSA',\n",
       " 'CAG',\n",
       " 'COP',\n",
       " 'ED',\n",
       " 'STZ',\n",
       " 'CEG',\n",
       " 'COO',\n",
       " 'CPRT',\n",
       " 'GLW',\n",
       " 'CPAY',\n",
       " 'CTVA',\n",
       " 'CSGP',\n",
       " 'COST',\n",
       " 'CTRA',\n",
       " 'CRWD',\n",
       " 'CCI',\n",
       " 'CSX',\n",
       " 'CMI',\n",
       " 'CVS',\n",
       " 'DHR',\n",
       " 'DRI',\n",
       " 'DDOG',\n",
       " 'DVA',\n",
       " 'DAY',\n",
       " 'DECK',\n",
       " 'DE',\n",
       " 'DELL',\n",
       " 'DAL',\n",
       " 'DVN',\n",
       " 'DXCM',\n",
       " 'FANG',\n",
       " 'DLR',\n",
       " 'DG',\n",
       " 'DLTR',\n",
       " 'D',\n",
       " 'DPZ',\n",
       " 'DASH',\n",
       " 'DOV',\n",
       " 'DOW',\n",
       " 'DHI',\n",
       " 'DTE',\n",
       " 'DUK',\n",
       " 'DD',\n",
       " 'EMN',\n",
       " 'ETN',\n",
       " 'EBAY',\n",
       " 'ECL',\n",
       " 'EIX',\n",
       " 'EW',\n",
       " 'EA',\n",
       " 'ELV',\n",
       " 'EME',\n",
       " 'EMR',\n",
       " 'ETR',\n",
       " 'EOG',\n",
       " 'EPAM',\n",
       " 'EQT',\n",
       " 'EFX',\n",
       " 'EQIX',\n",
       " 'EQR',\n",
       " 'ERIE',\n",
       " 'ESS',\n",
       " 'EL',\n",
       " 'EG',\n",
       " 'EVRG',\n",
       " 'ES',\n",
       " 'EXC',\n",
       " 'EXE',\n",
       " 'EXPE',\n",
       " 'EXPD',\n",
       " 'EXR',\n",
       " 'XOM',\n",
       " 'FFIV',\n",
       " 'FDS',\n",
       " 'FICO',\n",
       " 'FAST',\n",
       " 'FRT',\n",
       " 'FDX',\n",
       " 'FIS',\n",
       " 'FITB',\n",
       " 'FSLR',\n",
       " 'FE',\n",
       " 'FI',\n",
       " 'F',\n",
       " 'FTNT',\n",
       " 'FTV',\n",
       " 'FOXA',\n",
       " 'FOX',\n",
       " 'BEN',\n",
       " 'FCX',\n",
       " 'GRMN',\n",
       " 'IT',\n",
       " 'GE',\n",
       " 'GEHC',\n",
       " 'GEV',\n",
       " 'GEN',\n",
       " 'GNRC',\n",
       " 'GD',\n",
       " 'GIS',\n",
       " 'GM',\n",
       " 'GPC',\n",
       " 'GILD',\n",
       " 'GPN',\n",
       " 'GL',\n",
       " 'GDDY',\n",
       " 'GS',\n",
       " 'HAL',\n",
       " 'HIG',\n",
       " 'HAS',\n",
       " 'HCA',\n",
       " 'DOC',\n",
       " 'HSIC',\n",
       " 'HSY',\n",
       " 'HPE',\n",
       " 'HLT',\n",
       " 'HOLX',\n",
       " 'HD',\n",
       " 'HON',\n",
       " 'HRL',\n",
       " 'HST',\n",
       " 'HWM',\n",
       " 'HPQ',\n",
       " 'HUBB',\n",
       " 'HUM',\n",
       " 'HBAN',\n",
       " 'HII',\n",
       " 'IBM',\n",
       " 'IEX',\n",
       " 'IDXX',\n",
       " 'ITW',\n",
       " 'INCY',\n",
       " 'IR',\n",
       " 'PODD',\n",
       " 'INTC',\n",
       " 'IBKR',\n",
       " 'ICE',\n",
       " 'IFF',\n",
       " 'IP',\n",
       " 'IPG',\n",
       " 'INTU',\n",
       " 'ISRG',\n",
       " 'IVZ',\n",
       " 'INVH',\n",
       " 'IQV',\n",
       " 'IRM',\n",
       " 'JBHT',\n",
       " 'JBL',\n",
       " 'JKHY',\n",
       " 'J',\n",
       " 'JNJ',\n",
       " 'JCI',\n",
       " 'JPM',\n",
       " 'K',\n",
       " 'KVUE',\n",
       " 'KDP',\n",
       " 'KEY',\n",
       " 'KEYS',\n",
       " 'KMB',\n",
       " 'KIM',\n",
       " 'KMI',\n",
       " 'KKR',\n",
       " 'KLAC',\n",
       " 'KHC',\n",
       " 'KR',\n",
       " 'LHX',\n",
       " 'LH',\n",
       " 'LRCX',\n",
       " 'LW',\n",
       " 'LVS',\n",
       " 'LDOS',\n",
       " 'LEN',\n",
       " 'LII',\n",
       " 'LLY',\n",
       " 'LIN',\n",
       " 'LYV',\n",
       " 'LKQ',\n",
       " 'LMT',\n",
       " 'L',\n",
       " 'LOW',\n",
       " 'LULU',\n",
       " 'LYB',\n",
       " 'MTB',\n",
       " 'MPC',\n",
       " 'MAR',\n",
       " 'MMC',\n",
       " 'MLM',\n",
       " 'MAS',\n",
       " 'MA',\n",
       " 'MTCH',\n",
       " 'MKC',\n",
       " 'MCD',\n",
       " 'MCK',\n",
       " 'MDT',\n",
       " 'MRK',\n",
       " 'META',\n",
       " 'MET',\n",
       " 'MTD',\n",
       " 'MGM',\n",
       " 'MCHP',\n",
       " 'MU',\n",
       " 'MSFT',\n",
       " 'MAA',\n",
       " 'MRNA',\n",
       " 'MHK',\n",
       " 'MOH',\n",
       " 'TAP',\n",
       " 'MDLZ',\n",
       " 'MPWR',\n",
       " 'MNST',\n",
       " 'MCO',\n",
       " 'MS',\n",
       " 'MOS',\n",
       " 'MSI',\n",
       " 'MSCI',\n",
       " 'NDAQ',\n",
       " 'NTAP',\n",
       " 'NFLX',\n",
       " 'NEM',\n",
       " 'NWSA',\n",
       " 'NWS',\n",
       " 'NEE',\n",
       " 'NKE',\n",
       " 'NI',\n",
       " 'NDSN',\n",
       " 'NSC',\n",
       " 'NTRS',\n",
       " 'NOC',\n",
       " 'NCLH',\n",
       " 'NRG',\n",
       " 'NUE',\n",
       " 'NVDA',\n",
       " 'NVR',\n",
       " 'NXPI',\n",
       " 'ORLY',\n",
       " 'OXY',\n",
       " 'ODFL',\n",
       " 'OMC',\n",
       " 'ON',\n",
       " 'OKE',\n",
       " 'ORCL',\n",
       " 'OTIS',\n",
       " 'PCAR',\n",
       " 'PKG',\n",
       " 'PLTR',\n",
       " 'PANW',\n",
       " 'PSKY',\n",
       " 'PH',\n",
       " 'PAYX',\n",
       " 'PAYC',\n",
       " 'PYPL',\n",
       " 'PNR',\n",
       " 'PEP',\n",
       " 'PFE',\n",
       " 'PCG',\n",
       " 'PM',\n",
       " 'PSX',\n",
       " 'PNW',\n",
       " 'PNC',\n",
       " 'POOL',\n",
       " 'PPG',\n",
       " 'PPL',\n",
       " 'PFG',\n",
       " 'PG',\n",
       " 'PGR',\n",
       " 'PLD',\n",
       " 'PRU',\n",
       " 'PEG',\n",
       " 'PTC',\n",
       " 'PSA',\n",
       " 'PHM',\n",
       " 'PWR',\n",
       " 'QCOM',\n",
       " 'DGX',\n",
       " 'RL',\n",
       " 'RJF',\n",
       " 'RTX',\n",
       " 'O',\n",
       " 'REG',\n",
       " 'REGN',\n",
       " 'RF',\n",
       " 'RSG',\n",
       " 'RMD',\n",
       " 'RVTY',\n",
       " 'HOOD',\n",
       " 'ROK',\n",
       " 'ROL',\n",
       " 'ROP',\n",
       " 'ROST',\n",
       " 'RCL',\n",
       " 'SPGI',\n",
       " 'CRM',\n",
       " 'SBAC',\n",
       " 'SLB',\n",
       " 'STX',\n",
       " 'SRE',\n",
       " 'NOW',\n",
       " 'SHW',\n",
       " 'SPG',\n",
       " 'SWKS',\n",
       " 'SJM',\n",
       " 'SW',\n",
       " 'SNA',\n",
       " 'SOLS',\n",
       " 'SOLV',\n",
       " 'SO',\n",
       " 'LUV',\n",
       " 'SWK',\n",
       " 'SBUX',\n",
       " 'STT',\n",
       " 'STLD',\n",
       " 'STE',\n",
       " 'SYK',\n",
       " 'SMCI',\n",
       " 'SYF',\n",
       " 'SNPS',\n",
       " 'SYY',\n",
       " 'TMUS',\n",
       " 'TROW',\n",
       " 'TTWO',\n",
       " 'TPR',\n",
       " 'TRGP',\n",
       " 'TGT',\n",
       " 'TEL',\n",
       " 'TDY',\n",
       " 'TER',\n",
       " 'TSLA',\n",
       " 'TXN',\n",
       " 'TPL',\n",
       " 'TXT',\n",
       " 'TMO',\n",
       " 'TJX',\n",
       " 'TKO',\n",
       " 'TTD',\n",
       " 'TSCO',\n",
       " 'TT',\n",
       " 'TDG',\n",
       " 'TRV',\n",
       " 'TRMB',\n",
       " 'TFC',\n",
       " 'TYL',\n",
       " 'TSN',\n",
       " 'USB',\n",
       " 'UBER',\n",
       " 'UDR',\n",
       " 'ULTA',\n",
       " 'UNP',\n",
       " 'UAL',\n",
       " 'UPS',\n",
       " 'URI',\n",
       " 'UNH',\n",
       " 'UHS',\n",
       " 'VLO',\n",
       " 'VTR',\n",
       " 'VLTO',\n",
       " 'VRSN',\n",
       " 'VRSK',\n",
       " 'VZ',\n",
       " 'VRTX',\n",
       " 'VTRS',\n",
       " 'VICI',\n",
       " 'V',\n",
       " 'VST',\n",
       " 'VMC',\n",
       " 'WRB',\n",
       " 'GWW',\n",
       " 'WAB',\n",
       " 'WMT',\n",
       " 'DIS',\n",
       " 'WBD',\n",
       " 'WM',\n",
       " 'WAT',\n",
       " 'WEC',\n",
       " 'WFC',\n",
       " 'WELL',\n",
       " 'WST',\n",
       " 'WDC',\n",
       " 'WY',\n",
       " 'WSM',\n",
       " 'WMB',\n",
       " 'WTW',\n",
       " 'WDAY',\n",
       " 'WYNN',\n",
       " 'XEL',\n",
       " 'XYL',\n",
       " 'YUM',\n",
       " 'ZBRA',\n",
       " 'ZBH',\n",
       " 'ZTS']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69c011f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gathering earnings for MMM… ✅ done\n",
      "Gathering earnings for AOS… ✅ done\n",
      "Gathering earnings for ABT… ✅ done\n",
      "Gathering earnings for ABBV… ✅ done\n",
      "Gathering earnings for ACN… ✅ done\n",
      "Gathering earnings for ADBE… ✅ done\n",
      "Gathering earnings for AMD… ✅ done\n",
      "Gathering earnings for AES… ✅ done\n",
      "Gathering earnings for AFL… ✅ done\n",
      "Gathering earnings for A… ✅ done\n",
      "Gathering earnings for APD… ✅ done\n",
      "Gathering earnings for ABNB… ✅ done\n",
      "Gathering earnings for AKAM… ✅ done\n",
      "Gathering earnings for ALB… ✅ done\n",
      "Gathering earnings for ARE… ✅ done\n",
      "Gathering earnings for ALGN… ✅ done\n",
      "Gathering earnings for ALLE… ✅ done\n",
      "Gathering earnings for LNT… ✅ done\n",
      "Gathering earnings for ALL… ✅ done\n",
      "Gathering earnings for GOOGL… "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rahul\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\yfinance\\base.py:761: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['Earnings Date'] = pd.to_datetime(df['Event Start Date'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ done\n",
      "Gathering earnings for GOOG… ✅ done\n",
      "Gathering earnings for MO… ✅ done\n",
      "Gathering earnings for AMZN… ✅ done\n",
      "Gathering earnings for AMCR… ✅ done\n",
      "Gathering earnings for AEE… ✅ done\n",
      "Gathering earnings for AEP… ✅ done\n",
      "Gathering earnings for AXP… ✅ done\n",
      "Gathering earnings for AIG… ✅ done\n",
      "Gathering earnings for AMT… ✅ done\n",
      "Gathering earnings for AWK… ✅ done\n",
      "Gathering earnings for AMP… ✅ done\n",
      "Gathering earnings for AME… ✅ done\n",
      "Gathering earnings for AMGN… ✅ done\n",
      "Gathering earnings for APH… ✅ done\n",
      "Gathering earnings for ADI… ✅ done\n",
      "Gathering earnings for AON… ✅ done\n",
      "Gathering earnings for APA… ✅ done\n",
      "Gathering earnings for APO… ✅ done\n",
      "Gathering earnings for AAPL… ✅ done\n",
      "Gathering earnings for AMAT… ✅ done\n",
      "Gathering earnings for APP… ✅ done\n",
      "Gathering earnings for APTV… ✅ done\n",
      "Gathering earnings for ACGL… ✅ done\n",
      "Gathering earnings for ADM… ✅ done\n",
      "Gathering earnings for ANET… ✅ done\n",
      "Gathering earnings for AJG… ✅ done\n",
      "Gathering earnings for AIZ… ✅ done\n",
      "Gathering earnings for T… ✅ done\n",
      "Gathering earnings for ATO… ✅ done\n",
      "Gathering earnings for ADSK… ✅ done\n",
      "Gathering earnings for ADP… ✅ done\n",
      "Gathering earnings for AZO… ✅ done\n",
      "Gathering earnings for AVB… ✅ done\n",
      "Gathering earnings for AVY… ✅ done\n",
      "Gathering earnings for AXON… ✅ done\n",
      "Gathering earnings for BKR… ✅ done\n",
      "Gathering earnings for BALL… ✅ done\n",
      "Gathering earnings for BAC… ✅ done\n",
      "Gathering earnings for BAX… ✅ done\n",
      "Gathering earnings for BDX… ✅ done\n",
      "Gathering earnings for BRK-B… ✅ done\n",
      "Gathering earnings for BBY… ✅ done\n",
      "Gathering earnings for TECH… ✅ done\n",
      "Gathering earnings for BIIB… ✅ done\n",
      "Gathering earnings for BLK… ✅ done\n",
      "Gathering earnings for BX… ✅ done\n",
      "Gathering earnings for XYZ… ✅ done\n",
      "Gathering earnings for BK… ✅ done\n",
      "Gathering earnings for BA… ✅ done\n",
      "Gathering earnings for BKNG… ✅ done\n",
      "Gathering earnings for BSX… ✅ done\n",
      "Gathering earnings for BMY… ✅ done\n",
      "Gathering earnings for AVGO… ✅ done\n",
      "Gathering earnings for BR… ✅ done\n",
      "Gathering earnings for BRO… ✅ done\n",
      "Gathering earnings for BF-B… ✅ done\n",
      "Gathering earnings for BLDR… ✅ done\n",
      "Gathering earnings for BG… ✅ done\n",
      "Gathering earnings for BXP… ✅ done\n",
      "Gathering earnings for CHRW… ✅ done\n",
      "Gathering earnings for CDNS… ✅ done\n",
      "Gathering earnings for CPT… ✅ done\n",
      "Gathering earnings for CPB… ✅ done\n",
      "Gathering earnings for COF… ✅ done\n",
      "Gathering earnings for CAH… ✅ done\n",
      "Gathering earnings for CCL… ✅ done\n",
      "Gathering earnings for CARR… ✅ done\n",
      "Gathering earnings for CAT… ✅ done\n",
      "Gathering earnings for CBOE… ✅ done\n",
      "Gathering earnings for CBRE… ✅ done\n",
      "Gathering earnings for CDW… ✅ done\n",
      "Gathering earnings for COR… ✅ done\n",
      "Gathering earnings for CNC… ✅ done\n",
      "Gathering earnings for CNP… ✅ done\n",
      "Gathering earnings for CF… ✅ done\n",
      "Gathering earnings for CRL… ✅ done\n",
      "Gathering earnings for SCHW… ✅ done\n",
      "Gathering earnings for CHTR… ✅ done\n",
      "Gathering earnings for CVX… ✅ done\n",
      "Gathering earnings for CMG… ✅ done\n",
      "Gathering earnings for CB… ✅ done\n",
      "Gathering earnings for CHD… ✅ done\n",
      "Gathering earnings for CI… ✅ done\n",
      "Gathering earnings for CINF… ✅ done\n",
      "Gathering earnings for CTAS… ✅ done\n",
      "Gathering earnings for CSCO… ✅ done\n",
      "Gathering earnings for C… ✅ done\n",
      "Gathering earnings for CFG… ✅ done\n",
      "Gathering earnings for CLX… ✅ done\n",
      "Gathering earnings for CME… ✅ done\n",
      "Gathering earnings for CMS… ✅ done\n",
      "Gathering earnings for KO… ✅ done\n",
      "Gathering earnings for CTSH… ✅ done\n",
      "Gathering earnings for COIN… ✅ done\n",
      "Gathering earnings for CL… ✅ done\n",
      "Gathering earnings for CMCSA… ✅ done\n",
      "Gathering earnings for CAG… ✅ done\n",
      "Gathering earnings for COP… ✅ done\n",
      "Gathering earnings for ED… ✅ done\n",
      "Gathering earnings for STZ… ✅ done\n",
      "Gathering earnings for CEG… ✅ done\n",
      "Gathering earnings for COO… ✅ done\n",
      "Gathering earnings for CPRT… ✅ done\n",
      "Gathering earnings for GLW… ✅ done\n",
      "Gathering earnings for CPAY… ✅ done\n",
      "Gathering earnings for CTVA… ✅ done\n",
      "Gathering earnings for CSGP… ✅ done\n",
      "Gathering earnings for COST… ✅ done\n",
      "Gathering earnings for CTRA… ✅ done\n",
      "Gathering earnings for CRWD… ✅ done\n",
      "Gathering earnings for CCI… ✅ done\n",
      "Gathering earnings for CSX… ✅ done\n",
      "Gathering earnings for CMI… ✅ done\n",
      "Gathering earnings for CVS… ✅ done\n",
      "Gathering earnings for DHR… ✅ done\n",
      "Gathering earnings for DRI… ✅ done\n",
      "Gathering earnings for DDOG… ✅ done\n",
      "Gathering earnings for DVA… ✅ done\n",
      "Gathering earnings for DAY… ✅ done\n",
      "Gathering earnings for DECK… ✅ done\n",
      "Gathering earnings for DE… ✅ done\n",
      "Gathering earnings for DELL… ✅ done\n",
      "Gathering earnings for DAL… ✅ done\n",
      "Gathering earnings for DVN… ✅ done\n",
      "Gathering earnings for DXCM… ✅ done\n",
      "Gathering earnings for FANG… ✅ done\n",
      "Gathering earnings for DLR… ✅ done\n",
      "Gathering earnings for DG… ✅ done\n",
      "Gathering earnings for DLTR… ✅ done\n",
      "Gathering earnings for D… ✅ done\n",
      "Gathering earnings for DPZ… ✅ done\n",
      "Gathering earnings for DASH… ✅ done\n",
      "Gathering earnings for DOV… ✅ done\n",
      "Gathering earnings for DOW… ✅ done\n",
      "Gathering earnings for DHI… ✅ done\n",
      "Gathering earnings for DTE… ✅ done\n",
      "Gathering earnings for DUK… ✅ done\n",
      "Gathering earnings for DD… ✅ done\n",
      "Gathering earnings for EMN… ✅ done\n",
      "Gathering earnings for ETN… ✅ done\n",
      "Gathering earnings for EBAY… ✅ done\n",
      "Gathering earnings for ECL… ✅ done\n",
      "Gathering earnings for EIX… ✅ done\n",
      "Gathering earnings for EW… ✅ done\n",
      "Gathering earnings for EA… ✅ done\n",
      "Gathering earnings for ELV… ✅ done\n",
      "Gathering earnings for EME… ✅ done\n",
      "Gathering earnings for EMR… ✅ done\n",
      "Gathering earnings for ETR… ✅ done\n",
      "Gathering earnings for EOG… ✅ done\n",
      "Gathering earnings for EPAM… ✅ done\n",
      "Gathering earnings for EQT… ✅ done\n",
      "Gathering earnings for EFX… ✅ done\n",
      "Gathering earnings for EQIX… ✅ done\n",
      "Gathering earnings for EQR… ✅ done\n",
      "Gathering earnings for ERIE… ✅ done\n",
      "Gathering earnings for ESS… ✅ done\n",
      "Gathering earnings for EL… ✅ done\n",
      "Gathering earnings for EG… ✅ done\n",
      "Gathering earnings for EVRG… ✅ done\n",
      "Gathering earnings for ES… ✅ done\n",
      "Gathering earnings for EXC… ✅ done\n",
      "Gathering earnings for EXE… ✅ done\n",
      "Gathering earnings for EXPE… ✅ done\n",
      "Gathering earnings for EXPD… ✅ done\n",
      "Gathering earnings for EXR… ✅ done\n",
      "Gathering earnings for XOM… ✅ done\n",
      "Gathering earnings for FFIV… ✅ done\n",
      "Gathering earnings for FDS… ✅ done\n",
      "Gathering earnings for FICO… ✅ done\n",
      "Gathering earnings for FAST… ✅ done\n",
      "Gathering earnings for FRT… ✅ done\n",
      "Gathering earnings for FDX… ✅ done\n",
      "Gathering earnings for FIS… ✅ done\n",
      "Gathering earnings for FITB… ✅ done\n",
      "Gathering earnings for FSLR… ✅ done\n",
      "Gathering earnings for FE… ✅ done\n",
      "Gathering earnings for FI… ✅ done\n",
      "Gathering earnings for F… ✅ done\n",
      "Gathering earnings for FTNT… ✅ done\n",
      "Gathering earnings for FTV… ✅ done\n",
      "Gathering earnings for FOXA… "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FOX: $FOX: possibly delisted; no earnings dates found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ done\n",
      "Gathering earnings for FOX… ⚠️  No data — skipping\n",
      "Gathering earnings for BEN… ✅ done\n",
      "Gathering earnings for FCX… ✅ done\n",
      "Gathering earnings for GRMN… ✅ done\n",
      "Gathering earnings for IT… ✅ done\n",
      "Gathering earnings for GE… ✅ done\n",
      "Gathering earnings for GEHC… ✅ done\n",
      "Gathering earnings for GEV… ✅ done\n",
      "Gathering earnings for GEN… ✅ done\n",
      "Gathering earnings for GNRC… ✅ done\n",
      "Gathering earnings for GD… ✅ done\n",
      "Gathering earnings for GIS… ✅ done\n",
      "Gathering earnings for GM… ✅ done\n",
      "Gathering earnings for GPC… ✅ done\n",
      "Gathering earnings for GILD… ✅ done\n",
      "Gathering earnings for GPN… ✅ done\n",
      "Gathering earnings for GL… ✅ done\n",
      "Gathering earnings for GDDY… ✅ done\n",
      "Gathering earnings for GS… ✅ done\n",
      "Gathering earnings for HAL… ✅ done\n",
      "Gathering earnings for HIG… ✅ done\n",
      "Gathering earnings for HAS… ✅ done\n",
      "Gathering earnings for HCA… ✅ done\n",
      "Gathering earnings for DOC… ✅ done\n",
      "Gathering earnings for HSIC… ✅ done\n",
      "Gathering earnings for HSY… ✅ done\n",
      "Gathering earnings for HPE… ✅ done\n",
      "Gathering earnings for HLT… ✅ done\n",
      "Gathering earnings for HOLX… ✅ done\n",
      "Gathering earnings for HD… ✅ done\n",
      "Gathering earnings for HON… ✅ done\n",
      "Gathering earnings for HRL… ✅ done\n",
      "Gathering earnings for HST… ✅ done\n",
      "Gathering earnings for HWM… ✅ done\n",
      "Gathering earnings for HPQ… ✅ done\n",
      "Gathering earnings for HUBB… ✅ done\n",
      "Gathering earnings for HUM… ✅ done\n",
      "Gathering earnings for HBAN… ✅ done\n",
      "Gathering earnings for HII… ✅ done\n",
      "Gathering earnings for IBM… ✅ done\n",
      "Gathering earnings for IEX… ✅ done\n",
      "Gathering earnings for IDXX… ✅ done\n",
      "Gathering earnings for ITW… ✅ done\n",
      "Gathering earnings for INCY… ✅ done\n",
      "Gathering earnings for IR… ✅ done\n",
      "Gathering earnings for PODD… ✅ done\n",
      "Gathering earnings for INTC… ✅ done\n",
      "Gathering earnings for IBKR… ✅ done\n",
      "Gathering earnings for ICE… ✅ done\n",
      "Gathering earnings for IFF… ✅ done\n",
      "Gathering earnings for IP… ✅ done\n",
      "Gathering earnings for IPG… ✅ done\n",
      "Gathering earnings for INTU… ✅ done\n",
      "Gathering earnings for ISRG… ✅ done\n",
      "Gathering earnings for IVZ… ✅ done\n",
      "Gathering earnings for INVH… ✅ done\n",
      "Gathering earnings for IQV… ✅ done\n",
      "Gathering earnings for IRM… ✅ done\n",
      "Gathering earnings for JBHT… ✅ done\n",
      "Gathering earnings for JBL… ✅ done\n",
      "Gathering earnings for JKHY… ✅ done\n",
      "Gathering earnings for J… ✅ done\n",
      "Gathering earnings for JNJ… ✅ done\n",
      "Gathering earnings for JCI… ✅ done\n",
      "Gathering earnings for JPM… ✅ done\n",
      "Gathering earnings for K… ✅ done\n",
      "Gathering earnings for KVUE… ✅ done\n",
      "Gathering earnings for KDP… ✅ done\n",
      "Gathering earnings for KEY… ✅ done\n",
      "Gathering earnings for KEYS… ✅ done\n",
      "Gathering earnings for KMB… ✅ done\n",
      "Gathering earnings for KIM… ✅ done\n",
      "Gathering earnings for KMI… ✅ done\n",
      "Gathering earnings for KKR… ✅ done\n",
      "Gathering earnings for KLAC… ✅ done\n",
      "Gathering earnings for KHC… ✅ done\n",
      "Gathering earnings for KR… ✅ done\n",
      "Gathering earnings for LHX… ✅ done\n",
      "Gathering earnings for LH… ✅ done\n",
      "Gathering earnings for LRCX… ✅ done\n",
      "Gathering earnings for LW… ✅ done\n",
      "Gathering earnings for LVS… ✅ done\n",
      "Gathering earnings for LDOS… ✅ done\n",
      "Gathering earnings for LEN… ✅ done\n",
      "Gathering earnings for LII… ✅ done\n",
      "Gathering earnings for LLY… ✅ done\n",
      "Gathering earnings for LIN… ✅ done\n",
      "Gathering earnings for LYV… ✅ done\n",
      "Gathering earnings for LKQ… ✅ done\n",
      "Gathering earnings for LMT… ✅ done\n",
      "Gathering earnings for L… ✅ done\n",
      "Gathering earnings for LOW… ✅ done\n",
      "Gathering earnings for LULU… ✅ done\n",
      "Gathering earnings for LYB… ✅ done\n",
      "Gathering earnings for MTB… ✅ done\n",
      "Gathering earnings for MPC… ✅ done\n",
      "Gathering earnings for MAR… ✅ done\n",
      "Gathering earnings for MMC… ✅ done\n",
      "Gathering earnings for MLM… ✅ done\n",
      "Gathering earnings for MAS… ✅ done\n",
      "Gathering earnings for MA… ✅ done\n",
      "Gathering earnings for MTCH… ✅ done\n",
      "Gathering earnings for MKC… ✅ done\n",
      "Gathering earnings for MCD… ✅ done\n",
      "Gathering earnings for MCK… ✅ done\n",
      "Gathering earnings for MDT… ✅ done\n",
      "Gathering earnings for MRK… ✅ done\n",
      "Gathering earnings for META… ✅ done\n",
      "Gathering earnings for MET… ✅ done\n",
      "Gathering earnings for MTD… ✅ done\n",
      "Gathering earnings for MGM… ✅ done\n",
      "Gathering earnings for MCHP… ✅ done\n",
      "Gathering earnings for MU… ✅ done\n",
      "Gathering earnings for MSFT… ✅ done\n",
      "Gathering earnings for MAA… ✅ done\n",
      "Gathering earnings for MRNA… ✅ done\n",
      "Gathering earnings for MHK… ✅ done\n",
      "Gathering earnings for MOH… ✅ done\n",
      "Gathering earnings for TAP… ✅ done\n",
      "Gathering earnings for MDLZ… ✅ done\n",
      "Gathering earnings for MPWR… ✅ done\n",
      "Gathering earnings for MNST… ✅ done\n",
      "Gathering earnings for MCO… ✅ done\n",
      "Gathering earnings for MS… ✅ done\n",
      "Gathering earnings for MOS… ✅ done\n",
      "Gathering earnings for MSI… ✅ done\n",
      "Gathering earnings for MSCI… ✅ done\n",
      "Gathering earnings for NDAQ… ✅ done\n",
      "Gathering earnings for NTAP… ✅ done\n",
      "Gathering earnings for NFLX… ✅ done\n",
      "Gathering earnings for NEM… ✅ done\n",
      "Gathering earnings for NWSA… "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NWS: $NWS: possibly delisted; no earnings dates found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ done\n",
      "Gathering earnings for NWS… ⚠️  No data — skipping\n",
      "Gathering earnings for NEE… ✅ done\n",
      "Gathering earnings for NKE… ✅ done\n",
      "Gathering earnings for NI… ✅ done\n",
      "Gathering earnings for NDSN… ✅ done\n",
      "Gathering earnings for NSC… ✅ done\n",
      "Gathering earnings for NTRS… ✅ done\n",
      "Gathering earnings for NOC… ✅ done\n",
      "Gathering earnings for NCLH… ✅ done\n",
      "Gathering earnings for NRG… ✅ done\n",
      "Gathering earnings for NUE… ✅ done\n",
      "Gathering earnings for NVDA… ✅ done\n",
      "Gathering earnings for NVR… ✅ done\n",
      "Gathering earnings for NXPI… ✅ done\n",
      "Gathering earnings for ORLY… ✅ done\n",
      "Gathering earnings for OXY… ✅ done\n",
      "Gathering earnings for ODFL… ✅ done\n",
      "Gathering earnings for OMC… ✅ done\n",
      "Gathering earnings for ON… ✅ done\n",
      "Gathering earnings for OKE… ✅ done\n",
      "Gathering earnings for ORCL… ✅ done\n",
      "Gathering earnings for OTIS… ✅ done\n",
      "Gathering earnings for PCAR… ✅ done\n",
      "Gathering earnings for PKG… ✅ done\n",
      "Gathering earnings for PLTR… ✅ done\n",
      "Gathering earnings for PANW… ✅ done\n",
      "Gathering earnings for PSKY… "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PSKY: $PSKY: possibly delisted; no earnings dates found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️  No data — skipping\n",
      "Gathering earnings for PH… ✅ done\n",
      "Gathering earnings for PAYX… ✅ done\n",
      "Gathering earnings for PAYC… ✅ done\n",
      "Gathering earnings for PYPL… ✅ done\n",
      "Gathering earnings for PNR… ✅ done\n",
      "Gathering earnings for PEP… ✅ done\n",
      "Gathering earnings for PFE… ✅ done\n",
      "Gathering earnings for PCG… ✅ done\n",
      "Gathering earnings for PM… ✅ done\n",
      "Gathering earnings for PSX… ✅ done\n",
      "Gathering earnings for PNW… ✅ done\n",
      "Gathering earnings for PNC… ✅ done\n",
      "Gathering earnings for POOL… ✅ done\n",
      "Gathering earnings for PPG… ✅ done\n",
      "Gathering earnings for PPL… ✅ done\n",
      "Gathering earnings for PFG… ✅ done\n",
      "Gathering earnings for PG… ✅ done\n",
      "Gathering earnings for PGR… ✅ done\n",
      "Gathering earnings for PLD… ✅ done\n",
      "Gathering earnings for PRU… ✅ done\n",
      "Gathering earnings for PEG… ✅ done\n",
      "Gathering earnings for PTC… ✅ done\n",
      "Gathering earnings for PSA… ✅ done\n",
      "Gathering earnings for PHM… ✅ done\n",
      "Gathering earnings for PWR… ✅ done\n",
      "Gathering earnings for QCOM… ✅ done\n",
      "Gathering earnings for DGX… ✅ done\n",
      "Gathering earnings for RL… ✅ done\n",
      "Gathering earnings for RJF… ✅ done\n",
      "Gathering earnings for RTX… ✅ done\n",
      "Gathering earnings for O… ✅ done\n",
      "Gathering earnings for REG… ✅ done\n",
      "Gathering earnings for REGN… ✅ done\n",
      "Gathering earnings for RF… ✅ done\n",
      "Gathering earnings for RSG… ✅ done\n",
      "Gathering earnings for RMD… ✅ done\n",
      "Gathering earnings for RVTY… ✅ done\n",
      "Gathering earnings for HOOD… ✅ done\n",
      "Gathering earnings for ROK… ✅ done\n",
      "Gathering earnings for ROL… ✅ done\n",
      "Gathering earnings for ROP… ✅ done\n",
      "Gathering earnings for ROST… ✅ done\n",
      "Gathering earnings for RCL… ✅ done\n",
      "Gathering earnings for SPGI… ✅ done\n",
      "Gathering earnings for CRM… ✅ done\n",
      "Gathering earnings for SBAC… ✅ done\n",
      "Gathering earnings for SLB… ✅ done\n",
      "Gathering earnings for STX… ✅ done\n",
      "Gathering earnings for SRE… ✅ done\n",
      "Gathering earnings for NOW… ✅ done\n",
      "Gathering earnings for SHW… ✅ done\n",
      "Gathering earnings for SPG… ✅ done\n",
      "Gathering earnings for SWKS… ✅ done\n",
      "Gathering earnings for SJM… ✅ done\n",
      "Gathering earnings for SW… ✅ done\n",
      "Gathering earnings for SNA… ✅ done\n",
      "Gathering earnings for SOLS… "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SOLS: $SOLS: possibly delisted; no earnings dates found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️  No data — skipping\n",
      "Gathering earnings for SOLV… ✅ done\n",
      "Gathering earnings for SO… ✅ done\n",
      "Gathering earnings for LUV… ✅ done\n",
      "Gathering earnings for SWK… ✅ done\n",
      "Gathering earnings for SBUX… ✅ done\n",
      "Gathering earnings for STT… ✅ done\n",
      "Gathering earnings for STLD… ✅ done\n",
      "Gathering earnings for STE… ✅ done\n",
      "Gathering earnings for SYK… ✅ done\n",
      "Gathering earnings for SMCI… ✅ done\n",
      "Gathering earnings for SYF… ✅ done\n",
      "Gathering earnings for SNPS… ✅ done\n",
      "Gathering earnings for SYY… ✅ done\n",
      "Gathering earnings for TMUS… ✅ done\n",
      "Gathering earnings for TROW… ✅ done\n",
      "Gathering earnings for TTWO… ✅ done\n",
      "Gathering earnings for TPR… ✅ done\n",
      "Gathering earnings for TRGP… ✅ done\n",
      "Gathering earnings for TGT… ✅ done\n",
      "Gathering earnings for TEL… ✅ done\n",
      "Gathering earnings for TDY… ✅ done\n",
      "Gathering earnings for TER… ✅ done\n",
      "Gathering earnings for TSLA… ✅ done\n",
      "Gathering earnings for TXN… ✅ done\n",
      "Gathering earnings for TPL… ✅ done\n",
      "Gathering earnings for TXT… ✅ done\n",
      "Gathering earnings for TMO… ✅ done\n",
      "Gathering earnings for TJX… ✅ done\n",
      "Gathering earnings for TKO… ✅ done\n",
      "Gathering earnings for TTD… ✅ done\n",
      "Gathering earnings for TSCO… ✅ done\n",
      "Gathering earnings for TT… ✅ done\n",
      "Gathering earnings for TDG… ✅ done\n",
      "Gathering earnings for TRV… ✅ done\n",
      "Gathering earnings for TRMB… ✅ done\n",
      "Gathering earnings for TFC… ✅ done\n",
      "Gathering earnings for TYL… ✅ done\n",
      "Gathering earnings for TSN… ✅ done\n",
      "Gathering earnings for USB… ✅ done\n",
      "Gathering earnings for UBER… ✅ done\n",
      "Gathering earnings for UDR… ✅ done\n",
      "Gathering earnings for ULTA… ✅ done\n",
      "Gathering earnings for UNP… ✅ done\n",
      "Gathering earnings for UAL… ✅ done\n",
      "Gathering earnings for UPS… ✅ done\n",
      "Gathering earnings for URI… ✅ done\n",
      "Gathering earnings for UNH… ✅ done\n",
      "Gathering earnings for UHS… ✅ done\n",
      "Gathering earnings for VLO… ✅ done\n",
      "Gathering earnings for VTR… ✅ done\n",
      "Gathering earnings for VLTO… ✅ done\n",
      "Gathering earnings for VRSN… ✅ done\n",
      "Gathering earnings for VRSK… ✅ done\n",
      "Gathering earnings for VZ… ✅ done\n",
      "Gathering earnings for VRTX… ✅ done\n",
      "Gathering earnings for VTRS… ✅ done\n",
      "Gathering earnings for VICI… ✅ done\n",
      "Gathering earnings for V… ✅ done\n",
      "Gathering earnings for VST… ✅ done\n",
      "Gathering earnings for VMC… ✅ done\n",
      "Gathering earnings for WRB… ✅ done\n",
      "Gathering earnings for GWW… ✅ done\n",
      "Gathering earnings for WAB… ✅ done\n",
      "Gathering earnings for WMT… ✅ done\n",
      "Gathering earnings for DIS… ✅ done\n",
      "Gathering earnings for WBD… ✅ done\n",
      "Gathering earnings for WM… ✅ done\n",
      "Gathering earnings for WAT… ✅ done\n",
      "Gathering earnings for WEC… ✅ done\n",
      "Gathering earnings for WFC… ✅ done\n",
      "Gathering earnings for WELL… ✅ done\n",
      "Gathering earnings for WST… ✅ done\n",
      "Gathering earnings for WDC… ✅ done\n",
      "Gathering earnings for WY… ✅ done\n",
      "Gathering earnings for WSM… ✅ done\n",
      "Gathering earnings for WMB… ✅ done\n",
      "Gathering earnings for WTW… ✅ done\n",
      "Gathering earnings for WDAY… ✅ done\n",
      "Gathering earnings for WYNN… ✅ done\n",
      "Gathering earnings for XEL… ✅ done\n",
      "Gathering earnings for XYL… ✅ done\n",
      "Gathering earnings for YUM… ✅ done\n",
      "Gathering earnings for ZBRA… ✅ done\n",
      "Gathering earnings for ZBH… ✅ done\n",
      "Gathering earnings for ZTS… ✅ done\n",
      "\n",
      "✅ Total valid earnings events: 5901\n",
      "🚫 Skipped 4 tickers with no data: ['FOX', 'NWS', 'PSKY', 'SOLS']…\n"
     ]
    }
   ],
   "source": [
    "bad_tickers = []\n",
    "events = []\n",
    "\n",
    "for t in tickers:\n",
    "    try:\n",
    "        print(f\"Gathering earnings for {t}…\", end=\" \")\n",
    "\n",
    "        ticker_obj = yf.Ticker(t)\n",
    "        ed = ticker_obj.earnings_dates\n",
    "\n",
    "        # skip if None or empty DataFrame\n",
    "        if ed is None or ed.empty:\n",
    "            print(\"⚠️  No data — skipping\")\n",
    "            bad_tickers.append(t)\n",
    "            continue\n",
    "\n",
    "        ed = ed.reset_index()\n",
    "        ed.columns = [\"Date\", \"Estimate\", \"Reported\", \"Surprise_%\"]\n",
    "\n",
    "        # normalize dates\n",
    "        ed[\"Date\"] = ed[\"Date\"].dt.tz_localize(None).dt.normalize()\n",
    "        ed[\"Ticker\"] = t\n",
    "        events.append(ed[[\"Date\", \"Ticker\"]])\n",
    "        print(\"✅ done\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error: {e}\")\n",
    "        bad_tickers.append(t)\n",
    "        continue\n",
    "\n",
    "# Combine all successful results\n",
    "if events:\n",
    "    earnings_dates = pd.concat(events, ignore_index=True)\n",
    "    earnings_dates = earnings_dates[\n",
    "        (earnings_dates[\"Date\"] >= pd.to_datetime(start_date))\n",
    "        & (earnings_dates[\"Date\"] <= pd.to_datetime(end_date))\n",
    "    ].sort_values([\"Date\", \"Ticker\"]).reset_index(drop=True)\n",
    "else:\n",
    "    earnings_dates = pd.DataFrame(columns=[\"Date\", \"Ticker\"])\n",
    "\n",
    "print(f\"\\n✅ Total valid earnings events: {len(earnings_dates)}\")\n",
    "print(f\"🚫 Skipped {len(bad_tickers)} tickers with no data: {bad_tickers[:10]}…\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1dd2256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 499 valid tickers (skipping 4 bad ones)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rahul\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\yfinance\\base.py:761: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['Earnings Date'] = pd.to_datetime(df['Event Start Date'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Total earnings events (with Surprise_%): 5901\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Surprise_%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-11-01</td>\n",
       "      <td>L</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-02-07</td>\n",
       "      <td>L</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-05-03</td>\n",
       "      <td>SMCI</td>\n",
       "      <td>38.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-06-30</td>\n",
       "      <td>STZ</td>\n",
       "      <td>5.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-07-12</td>\n",
       "      <td>PEP</td>\n",
       "      <td>7.11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date Ticker  Surprise_%\n",
       "0 2021-11-01      L         NaN\n",
       "1 2022-02-07      L         NaN\n",
       "2 2022-05-03   SMCI       38.70\n",
       "3 2022-06-30    STZ        5.89\n",
       "4 2022-07-12    PEP        7.11"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 2 — Build unified earnings_dates with Surprise_% included\n",
    "events = []\n",
    "\n",
    "# Filter tickers to exclude those with no data (collected earlier)\n",
    "good_tickers = [t for t in tickers if t not in bad_tickers]\n",
    "print(f\"Processing {len(good_tickers)} valid tickers (skipping {len(bad_tickers)} bad ones)\")\n",
    "\n",
    "for t in good_tickers:\n",
    "    try:\n",
    "        ed = yf.Ticker(t).earnings_dates\n",
    "        if ed is None or ed.empty:\n",
    "            print(f\"⚠️  No earnings data for {t} — skipping\")\n",
    "            bad_tickers.append(t)\n",
    "            continue\n",
    "\n",
    "        ed = ed.reset_index()\n",
    "        ed.columns = [\"Date\", \"Earnings_Estimate\", \"Reported_Earnings\", \"Surprise_%\"]\n",
    "        ed[\"Date\"] = ed[\"Date\"].dt.tz_localize(None).dt.normalize()\n",
    "        ed[\"Ticker\"] = t\n",
    "        events.append(ed[[\"Date\", \"Ticker\", \"Surprise_%\"]])\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ {t}: {e}\")\n",
    "        bad_tickers.append(t)\n",
    "        continue\n",
    "\n",
    "earnings_dates = (\n",
    "    pd.concat(events, ignore_index=True)\n",
    "      .query(\"@start_date <= Date <= @end_date\")\n",
    "      .sort_values([\"Date\", \"Ticker\"])\n",
    "      .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "print(f\"✅ Total earnings events (with Surprise_%): {len(earnings_dates)}\")\n",
    "display(earnings_dates.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a292de65",
   "metadata": {},
   "source": [
    "## Step 3: Feature Engineering Per Ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a671c758",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = []\n",
    "\n",
    "for t in tickers:\n",
    "    print(f\"  Engineering features for {t}…\")\n",
    "    df_t = raw[t].copy()  # slice out ticker\n",
    "    \n",
    "    # 1) flatten MultiIndex\n",
    "    if isinstance(df_t.columns, pd.MultiIndex):\n",
    "        df_t.columns = df_t.columns.get_level_values(0)\n",
    "    # 2) drop stray Price\n",
    "    df_t.drop(columns=[c for c in [\"Price\"] if c in df_t], inplace=True)\n",
    "    \n",
    "    # 3) coerce core series\n",
    "    df_t[\"Close\"]  = pd.to_numeric(df_t[\"Close\"],  errors=\"coerce\")\n",
    "    df_t[\"Volume\"] = pd.to_numeric(df_t[\"Volume\"], errors=\"coerce\")\n",
    "    df_t.dropna(subset=[\"Close\",\"Volume\"], inplace=True)\n",
    "    \n",
    "    # 4) basic features\n",
    "    df_t[\"Return\"]      = df_t[\"Close\"].pct_change()\n",
    "    df_t[\"Volatility\"]  = df_t[\"Return\"].rolling(5).std()\n",
    "    df_t[\"RSI\"]         = RSIIndicator(close=df_t[\"Close\"], window=14).rsi()\n",
    "    df_t[\"MA5\"]         = df_t[\"Close\"].rolling(5).mean()\n",
    "    df_t[\"MA10\"]        = df_t[\"Close\"].rolling(10).mean()\n",
    "    df_t[\"MA_ratio\"]    = df_t[\"MA5\"] / df_t[\"MA10\"] - 1\n",
    "    df_t[\"Volume_Avg20\"]= df_t[\"Volume\"].rolling(20).mean()\n",
    "    df_t[\"Volume_Spike\"]= df_t[\"Volume\"] / df_t[\"Volume_Avg20\"] - 1\n",
    "    \n",
    "    # 5) new predictive features\n",
    "    df_t[\"Momentum3\"]   = df_t[\"Close\"].pct_change(3)\n",
    "    atr = AverageTrueRange(high=df_t[\"High\"], low=df_t[\"Low\"], \n",
    "                           close=df_t[\"Close\"], window=14)\n",
    "    df_t[\"ATR14\"]       = atr.average_true_range()\n",
    "    df_t[\"DayOfWeek\"]   = df_t.index.dayofweek\n",
    "    df_t[\"Month\"]       = df_t.index.month\n",
    "\n",
    "    # ——— HERE: merge in Surprise_% from your earnings_dates ———\n",
    "    # slice out only this ticker’s surprises\n",
    "    ed_t = (\n",
    "        earnings_dates\n",
    "        .loc[earnings_dates[\"Ticker\"] == t, [\"Date\",\"Surprise_%\"]]\n",
    "        .set_index(\"Date\")\n",
    "    )\n",
    "    # align on the same dates, left‐join so non-event days get NaN\n",
    "    df_t = df_t.join(ed_t, how=\"left\")\n",
    "    # fill non‐events with zero surprise\n",
    "    df_t[\"Surprise_%\"] = df_t[\"Surprise_%\"].fillna(0)\n",
    "    \n",
    "    # 6) drop NaNs from rolling/pct_change (but keep Surprise_% zeros)\n",
    "    df_t.dropna(subset=[\n",
    "        \"Return\",\"Volatility\",\"RSI\",\"MA5\",\"MA10\",\"MA_ratio\",\n",
    "        \"Volume_Avg20\",\"Volume_Spike\",\"Momentum3\",\"ATR14\"\n",
    "    ], inplace=True)\n",
    "    \n",
    "    # 7) select your expanded feature set\n",
    "    keep = [\n",
    "        \"Close\",\"Volume\",\n",
    "        \"Return\",\"Volatility\",\"RSI\",\n",
    "        \"MA5\",\"MA10\",\"MA_ratio\",\n",
    "        \"Volume_Avg20\",\"Volume_Spike\",\n",
    "        \"Momentum3\",\"ATR14\",\n",
    "        \"DayOfWeek\",\"Month\",\n",
    "        \"Surprise_%\"\n",
    "    ]\n",
    "    feats = df_t[keep].copy()\n",
    "    feats[\"Ticker\"] = t\n",
    "    feature_list.append(feats)\n",
    "\n",
    "# concatenate all tickers\n",
    "features_df = pd.concat(feature_list)\n",
    "features_df.index.name = \"Date\"\n",
    "features_df = features_df.sort_index()\n",
    "\n",
    "print(\"Features shape (all tickers):\", features_df.shape)\n",
    "display(features_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10473331",
   "metadata": {},
   "source": [
    "## Step 4: Create Event-Only Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6c1d5548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labeled 2963 events:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-07-28</td>\n",
       "      <td>KIM</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-08-01</td>\n",
       "      <td>SPG</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-08-04</td>\n",
       "      <td>FRT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-08-17</td>\n",
       "      <td>AMCR</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-10-27</td>\n",
       "      <td>AOS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2958</th>\n",
       "      <td>2024-12-19</td>\n",
       "      <td>KMX</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2959</th>\n",
       "      <td>2024-12-19</td>\n",
       "      <td>LW</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2960</th>\n",
       "      <td>2024-12-19</td>\n",
       "      <td>NKE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2961</th>\n",
       "      <td>2024-12-19</td>\n",
       "      <td>PAYX</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2962</th>\n",
       "      <td>2024-12-20</td>\n",
       "      <td>CCL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2963 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date Ticker  Target\n",
       "0    2022-07-28    KIM       1\n",
       "1    2022-08-01    SPG       0\n",
       "2    2022-08-04    FRT       1\n",
       "3    2022-08-17   AMCR       0\n",
       "4    2022-10-27    AOS       1\n",
       "...         ...    ...     ...\n",
       "2958 2024-12-19    KMX       1\n",
       "2959 2024-12-19     LW       0\n",
       "2960 2024-12-19    NKE       0\n",
       "2961 2024-12-19   PAYX       1\n",
       "2962 2024-12-20    CCL       0\n",
       "\n",
       "[2963 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 4: Label creation (target variable) for multi‐ticker MultiIndex\n",
    "\n",
    "def create_labels(event_dates, price_df, horizon=3):\n",
    "    \"\"\"\n",
    "    event_dates: DataFrame with ['Date','Ticker'] columns of pd.Timestamps\n",
    "    price_df:    DataFrame with a MultiIndex (Date, Ticker) and at least a 'Close' column\n",
    "    horizon:     how many trading days ahead to look\n",
    "    \"\"\"\n",
    "    labels = []\n",
    "    # 1) pre‐shift the Close series within each ticker\n",
    "    future_close = price_df['Close'].groupby(level='Ticker').shift(-horizon)\n",
    "    \n",
    "    for _, ev in event_dates.iterrows():\n",
    "        dt, tkr = ev['Date'], ev['Ticker']\n",
    "        key = (dt, tkr)\n",
    "        # 2) skip if that (Date, Ticker) combo isn't in your features\n",
    "        if key not in price_df.index:\n",
    "            continue\n",
    "        \n",
    "        past = price_df.at[key, 'Close']\n",
    "        fut  = future_close.at[key]\n",
    "        # 3) skip if we ran off the end\n",
    "        if pd.isna(fut):\n",
    "            continue\n",
    "        \n",
    "        ret = (fut - past) / past\n",
    "        labels.append({\n",
    "          'Date':   dt,\n",
    "          'Ticker': tkr,\n",
    "          'Target': int(ret > 0)\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(labels)\n",
    "\n",
    "\n",
    "# — how to call it —\n",
    "# make sure features_df is a MultiIndexed DF: index names must be ['Date','Ticker']\n",
    "features_df = features_df.reset_index().set_index(['Date','Ticker'])\n",
    "\n",
    "labels_df = create_labels(earnings_dates, features_df, horizon=horizon)\n",
    "print(f\"Labeled {len(labels_df)} events:\")\n",
    "display(labels_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b05144",
   "metadata": {},
   "source": [
    "## Step 5: Merge features & labels for multi-ticker dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "84a4caf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final dataset shape: (2963, 17)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Return</th>\n",
       "      <th>Volatility</th>\n",
       "      <th>RSI</th>\n",
       "      <th>MA5</th>\n",
       "      <th>MA10</th>\n",
       "      <th>MA_ratio</th>\n",
       "      <th>Volume_Avg20</th>\n",
       "      <th>Volume_Spike</th>\n",
       "      <th>Momentum3</th>\n",
       "      <th>ATR14</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Month</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-07-28</td>\n",
       "      <td>KIM</td>\n",
       "      <td>21.860001</td>\n",
       "      <td>4028800.0</td>\n",
       "      <td>0.016744</td>\n",
       "      <td>0.013179</td>\n",
       "      <td>62.512911</td>\n",
       "      <td>21.498</td>\n",
       "      <td>21.180000</td>\n",
       "      <td>0.015014</td>\n",
       "      <td>3674420.0</td>\n",
       "      <td>0.096445</td>\n",
       "      <td>0.016272</td>\n",
       "      <td>0.522246</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-08-01</td>\n",
       "      <td>SPG</td>\n",
       "      <td>108.629997</td>\n",
       "      <td>1650100.0</td>\n",
       "      <td>-0.000092</td>\n",
       "      <td>0.017185</td>\n",
       "      <td>65.657759</td>\n",
       "      <td>106.286</td>\n",
       "      <td>104.909999</td>\n",
       "      <td>0.013116</td>\n",
       "      <td>1648115.0</td>\n",
       "      <td>0.001204</td>\n",
       "      <td>0.043315</td>\n",
       "      <td>2.614542</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-08-04</td>\n",
       "      <td>FRT</td>\n",
       "      <td>105.040001</td>\n",
       "      <td>797300.0</td>\n",
       "      <td>0.008352</td>\n",
       "      <td>0.009903</td>\n",
       "      <td>59.129102</td>\n",
       "      <td>104.944</td>\n",
       "      <td>103.873000</td>\n",
       "      <td>0.010311</td>\n",
       "      <td>644255.0</td>\n",
       "      <td>0.237553</td>\n",
       "      <td>-0.007090</td>\n",
       "      <td>2.419999</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-08-17</td>\n",
       "      <td>AMCR</td>\n",
       "      <td>13.010000</td>\n",
       "      <td>8882400.0</td>\n",
       "      <td>-0.021068</td>\n",
       "      <td>0.017779</td>\n",
       "      <td>56.644113</td>\n",
       "      <td>12.954</td>\n",
       "      <td>12.713000</td>\n",
       "      <td>0.018957</td>\n",
       "      <td>9221750.0</td>\n",
       "      <td>-0.036799</td>\n",
       "      <td>0.015613</td>\n",
       "      <td>0.295485</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-10-27</td>\n",
       "      <td>AOS</td>\n",
       "      <td>51.900002</td>\n",
       "      <td>1332100.0</td>\n",
       "      <td>-0.000962</td>\n",
       "      <td>0.014431</td>\n",
       "      <td>52.561661</td>\n",
       "      <td>51.376</td>\n",
       "      <td>50.882000</td>\n",
       "      <td>0.009709</td>\n",
       "      <td>1311860.0</td>\n",
       "      <td>0.015428</td>\n",
       "      <td>0.021654</td>\n",
       "      <td>1.601343</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date Ticker       Close     Volume    Return  Volatility        RSI  \\\n",
       "0 2022-07-28    KIM   21.860001  4028800.0  0.016744    0.013179  62.512911   \n",
       "1 2022-08-01    SPG  108.629997  1650100.0 -0.000092    0.017185  65.657759   \n",
       "2 2022-08-04    FRT  105.040001   797300.0  0.008352    0.009903  59.129102   \n",
       "3 2022-08-17   AMCR   13.010000  8882400.0 -0.021068    0.017779  56.644113   \n",
       "4 2022-10-27    AOS   51.900002  1332100.0 -0.000962    0.014431  52.561661   \n",
       "\n",
       "       MA5        MA10  MA_ratio  Volume_Avg20  Volume_Spike  Momentum3  \\\n",
       "0   21.498   21.180000  0.015014     3674420.0      0.096445   0.016272   \n",
       "1  106.286  104.909999  0.013116     1648115.0      0.001204   0.043315   \n",
       "2  104.944  103.873000  0.010311      644255.0      0.237553  -0.007090   \n",
       "3   12.954   12.713000  0.018957     9221750.0     -0.036799   0.015613   \n",
       "4   51.376   50.882000  0.009709     1311860.0      0.015428   0.021654   \n",
       "\n",
       "      ATR14  DayOfWeek  Month  Target  \n",
       "0  0.522246          3      7       1  \n",
       "1  2.614542          0      8       0  \n",
       "2  2.419999          3      8       1  \n",
       "3  0.295485          2      8       0  \n",
       "4  1.601343          3     10       1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved to multi_ticker_earnings_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "# 1) Ensure the feature and label DataFrames share the same MultiIndex\n",
    "#    (Date,Ticker) before joining:\n",
    "\n",
    "# features_df should already be indexed by (Date,Ticker)\n",
    "# if not, do it explicitly:\n",
    "features_df = features_df.reset_index().set_index(['Date','Ticker'])\n",
    "\n",
    "# labels_df just needs to have the same index\n",
    "labels_df = labels_df.set_index(['Date','Ticker'])\n",
    "\n",
    "# 2) Join on that MultiIndex, pulling in only the 'Target' column from labels_df\n",
    "final_df = features_df.join(\n",
    "    labels_df[['Target']],\n",
    "    how='inner'\n",
    ").reset_index()\n",
    "\n",
    "# 3) Inspect & save\n",
    "print(\"Final dataset shape:\", final_df.shape)\n",
    "display(final_df.head())\n",
    "\n",
    "final_df.to_csv(\"multi_ticker_earnings_dataset.csv\", index=False)\n",
    "print(\"✅ Saved to multi_ticker_earnings_dataset.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
